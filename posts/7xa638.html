<!DOCTYPE html>
<html lang="en">
<head>
	<link rel="stylesheet" type="text/less" href="/css/post.less">
	
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="shortcut icon" type="image/png" href="/img/cat.jpg"/>
	<script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/less.js/2.5.3/less.min.js"></script>
	<link href="https://fonts.googleapis.com/css?family=Roboto:400,700" rel="stylesheet">
	<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-58440568-4', 'auto');
		ga('send', 'pageview');
	</script>

	<!-- Cookie Consent plugin by Silktide - http://silktide.com/cookieconsent -->
	<script type="text/javascript">
    window.cookieconsent_options = {"message":"This website uses cookies to ensure you get the best experience on our website","dismiss":"Got it!","learnMore":"More info","link":null,"theme":"dark-bottom"};
	</script>
	<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/1.0.10/cookieconsent.min.js"></script>
	<title>Study &quot;Caffeine Caused a Widespread Increase of Resting Brain Entropy&quot; Well...what the heck is resting brain entropy? Is that good or bad? Google is not helping</title>
</head>
<body>
	<div id="header">
	<a href="/about" title="About">About</a>
</div>
	<div id="content">
		<div class="home">
			<a href="/">Back to Home</a>
		</div>

		<ul class="posts">
<li class="post" data-handle="7xa638">
	<div class="overview">
		<a class="source" href="https://www.reddit.com/r/askscience/comments/7xa638/study_caffeine_caused_a_widespread_increase_of/" target="_blank" title="Reddit thread where this comes from"><i class="fa fa-external-link" aria-hidden="true"></i></a>
		<h2>
			<span class="tags tag-Biology">Biology</span>
			<a href="/posts/7xa638" onclick="return false">Study &quot;Caffeine Caused a Widespread Increase of Resting Brain Entropy&quot; Well...what the heck is resting brain entropy? Is that good or bad? Google is not helping</a>
		</h2>
		<!--<span class="date">2018-02-16</span>-->
		<span class="is-new">NEW</span>
	</div>

		<div class="question"><span class="qa" title="Question">Q:</span><div class="markdown"><p>study shows increased resting brain entropy with caffeine ingestion </p>
<p><a href="https://www.nature.com/articles/s41598-018-21008-6" target="_blank">https://www.nature.com/articles/s41598-018-21008-6</a></p>
<p>first sentence indicates this would be a good thing </p>
<blockquote>
<p>Entropy is an important trait of brain function and high entropy indicates high information processing capacity. </p>
</blockquote>
<p>however if you google 'resting brain entropy' you will see high RBE is associated with alzheimers. </p>
<p>so...is RBE good or bad? caffeine good or bad for the brain? </p></div></div>

	<div class="comment-section">
		<div class="answers-placeholder">
			<div class="answers">
	<div class="answer" data-handle="du7eiza">
		<a class="author" href="https://www.reddit.com/user/Brodman_area11" target="_blank">Brodman_area11</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>Ph.D. in Psychology/neurophysiology here.  It's hard to reduce this to an ELI 5 level, but I'll give it a shot.  Say you're driving through a small, simple town with one street light at that town's rush hour: all the traffic will come up, pause, then go with a regular rhythm.  That would be a high degree of order (the opposite of entropy).  Not much communication or flexibility needed, and its the mental equivalent of a deep sleep.  If you compare that to downtown tokyo, there are people everywhere, going in all directions on foot and in cars and bikes, etc.  That's a lot of information flowing in many directions, and if we turn them in to brain cells they are busy, active, and adaptable.  Chaotic systems have more energy and more going on than simple systems, and we measure this in terms of entropy (which is honestly a misnomer, it's all meaningful, but the math for entropy works as a best model).  </p>
<p>All of this is fueled by blood flow to get oxygen to the cells, but it's not a 1:1 correlation.  Having said that, the main measure they used is a measurement of where water/blood goes in the brain (fMRI).  The study said that since caffine restricts blood flow, it should slow the brain down, but the chemical makes the cells all over the brain fire more easily, so lower blood flow but higher levels of cross-talk and entropy.  </p>
<p>So is it good or bad?  Yes.  It's good for the short term, making thinking more efficient and clear, but it's not good for the long term because you're making the cells work harder with less fuel.  </p>
<p>That also explain why withdrawal from caffine causes headaches, btw.  Withdrawal from a chemical causes the opposite of the chemical's effect, so when you don't drink coffee after getting addicted, the blood flow in the head increases, causing higher pressure, which leads to pain.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<a class="less-answers upper" href="javascript:void(0)">less answers...</a>
	<div class="answer" data-handle="du6xtjr">
		<a class="author" href="https://www.reddit.com/user/JimminyBibbles" target="_blank">JimminyBibbles</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>I couldn't understand peoples responses, so I did some research. Here is the best explanation I could find. </p>
<p>&quot;Human intelligence comprises comprehension of and reasoning about an infinitely variable external environment. A brain capable of large variability in neural configurations, or states, will more easily understand and predict variable external events. Entropy measures the variety of configurations possible within a system, and recently the concept of brain entropy has been defined as the number of neural states a given brain can access.&quot;</p>
<p><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191582" target="_blank">Link to article</a></p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="du76bbk">
		<a class="author" href="https://www.reddit.com/user/NeuroPsychotic" target="_blank">NeuroPsychotic</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>I tried to write as simple as possible my point of view on the topic, I don't know if it's clear or not, any comment will be appreciated. </p>
<p><a href="http://ieeexplore.ieee.org/document/709563/" target="_blank">Here</a> is the foundation for what the authors mean.</p>
<p>This article, far from being simple, describes how raw physiological signals give informations about the state in which the whole biological system lies. It's like checking if your car is in good shape by assessing wheel pressure, gas level, oil level etc. Putting together these different kinds of information for your car is simple (I have a full tank, pressure ok, oil in range, I'm good to go for another long trip), but at the biological level you can't just add up everything (I can't say, well GABAergic interneurons are firing regularly in the gyrus dentatus of the hyppocapus and the EEG looks normal, so the patient is ok), so you first need to estimate &quot;complexity&quot;. What's that? Intuitively, some signals will vary a lot during your observation (EEG recorded from a patient with dementia), some others not (action potentials are an all-or none phenomenon, and some cells have a very regular firing pattern). Fundamentally you might see some patterns that repeat themselves, accompanied by some absolute randomness. Back to your car, you know that filling up the tank will give you more journey time, but you can't predict when you'll get a flat tire (this analogy is a bit off topic, but is just to get the idea). </p>
<p>So, what about &quot;entropy&quot;? Entropy gives you an idea of the complexity of your system. Entropy measures the <em>uncertainty</em> of an event at a given time <em>t</em>: the lower the entropy, the more you are sure of what will come next. In a brain with high entropy you cannot predict what will come next (signal flow from one part of the brain does not result in a desired outcome in another part, again, rough example), in a brain with a too low entropy you have a fixed outcome for any action, and you don't want that also, because you cannot have remodeling necessary for, among others, learning. So the brain must lie in an intermediate state of entropy (Note that you cannot measure entropy <em>per se</em>, but only relative to another state), in that it must be capable of performing its function with a desired outcome. Finally, if caffeine causes an increase in brain entropy, now it should be clear that this means more &quot;disorder&quot; between brain signals (rawness alert), which translates into more capacity to adapt in response to inputs, more &quot;flexibility&quot; as a whole. in Alzheimer's disease this is taken to another level: structural destruction leads to too much chaos, and unpredictability on what will be the downstream effects.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="du6path">
		<a class="author" href="https://www.reddit.com/user/must-be-thursday" target="_blank">must-be-thursday</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>Were you able to read the whole paper? The first bit of the discussion is the clearest explanation:</p>
<blockquote>
<p>Complexity of temporal activity provides a unique window to study human brain, which is the most complex organism known to us. Temporal complexity indicates the capacity of brain for information processing and action exertions, and has been widely assessed with entropy though these two measures don’t always align with each other - complexity doesn’t increase monotonically with entropy but rather decreases with entropy after the system reaches the maximal point of irregularity.</p>
</blockquote>
<p>In a previous section, they also describe:</p>
<blockquote>
<p>The overall picture of a complex regime for neuronal dynamics–that lies somewhere between a low entropy coherent regime (such as coma or slow wave sleep) and a high entropy chaotic regime</p>
</blockquote>
<p>My interpretation: optimal brain function requires <em>complexity</em> which lies somewhere between a low entropy ordered state and a high entropy chaotic state. I'm not sure what the best analogy for this is, but it seems to make sense - if the brain is too 'ordered' then it can't do many different things at the same time, but at the other extreme a highly chaotic state just becomes white noise and it can't make meaningful patterns.</p>
<p>The authors of this paper suggest that by increasing BEN, caffeine increases complexity - i.e. before the caffeine the brain is below the optimal level of entropy. This would therefore be associated with an increase in function - although the authors didn't test this here. </p>
<p>It's possible that diseases such as alzheimers increase entropy even further and go past the optimal peak and decend into chaos - although I'm not familiar with that topic at all.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="du7hb5p">
		<a class="author" href="https://www.reddit.com/user/IWantUsToMerge" target="_blank">IWantUsToMerge</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>I think before people can get anything useful out of this, they're going to understand exactly what entropy is. I'm going to explain it in terms of code and computations. This might seem like a very different context. Maybe it is. Entropy is just a very broadly applicable idea. I think you'll be able to see how the ideas transfer to the context of cognition.</p>
<p>The entropy of a piece of information, is roughly the minimum possible size of a program that could generate that information. In other words, the entropy of a piece of information is the size of a complete description of it.</p>
<p>For example. The following two sequences have very different entropy, despite being the same length:</p>
<p>000010000100001000010000100001000010000100001000010000100001</p>
<p>011101010001011000010110010111110001010111111101010110001111</p>
<p>The first could be generated by a program like <code>loop 12 times { emit('00001') }</code>, a program that just says '00001' 12 times.</p>
<p>The second, as far as I can tell, can only be described with <code>emit('011101010001011000010110010111110001010111111101010110001111')</code>. It has the longer minimum generating-program, so it has higher entropy.</p>
<p>It's possible that a general purpose compression algorithm, or a hyperintelligent being, might be able to find a shorter description of the second sequence than we could, but there are always going to be sequences that even God could not compress.</p>
<p>It might now be intuitive to you, why low-entropy in thought might be a bad sign. A person who just thought '00001' over and over would be, what might be well described as a smooth-brain, no more sophisticated than a program that says the same thing again and again.</p>
<p>High entropy, too, is clearly not always a good thing. Entropy is at its highest when the process is purely random and nothing sensible is going on.</p></div>		<div class="replies-placeholder"></div>
	</div>
</div>		</div>
		<div class="more-less">
			<a class="collapse" href="javascript:void(0)">collapse</a>
			<a class="more-answers" href="javascript:void(0)">4 more answers...</a>
			<a class="less-answers lower" href="javascript:void(0)">less answers...</a>
			&nbsp;
		</div>
	</div>
	<a class="show" href="/posts/7xa638" onclick="return false"><span>show</span></a>
</li>
		</ul>
	</div>

	<script>
		var config = {"stream":{"initial":10,"catchup":5},"api":{"url":"api.veryinteresting.io"}};
	</script>
	<script src="/js/project.js"></script>
	<script src="/js/post.js"></script>
</body>
</html>