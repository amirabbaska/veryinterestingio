<div class="answers">
	<div class="answer" data-handle="cnd58da">
		<a class="author" href="https://www.reddit.com/user/PlayTheBanjo" target="_blank">PlayTheBanjo</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>It depends on the game, type of game, AI role, etc.</p>
<p>Is there a particular game or character you want to know more about?  I'll try to give a brief overview of a few topics (as I started explaining this, it became clear it was going to be long).</p>
<p><strong>Pathfinding:</strong> This is a big one.  Imagine a game like Starcraft, Warcraft 3, DotA, LoL, or any other game where you pick a unit/character/hero and tell them where to go.  How does it know the best way to get there?  Well, in an ideal world (the frictionless vacuum infinite plane world from high school physics class), they would just move in a straight line to the point.  Of course, this is often not the case.  Any interesting game will have impassible obstacles in the way or terrain that takes longer to traverse than others (maybe the unit has to pass through a thick swamp vs. a grassy plane, or the unit has to travel uphill).  One solution would be to calculate every possible path from every spot on the map to every other spot on the map, but this isn't always practical.  First of all, most RTS games aren't like a chessboard, but imagine that they are.  A chessboard is 8 spaces by 8 spaces for a total of 64 spaces.  Assuming there is a piece that can move any distance in any direction, each of the 64 squares will have 63 potential squares to which it can move in the most efficient way.  That means that you would have to pre-compute on the order of 64 choose 2 (or something, it's early here and I'm kind of hung over) which is over 2000 paths to compute, and that's assuming that there are no obstacles in the way and the piece can move through every square with equal ease.  Extrapolate that to a modern video game and the space-complexity of the &quot;board&quot; is far greater than 8x8.  In real life, the state-space will be continuous (there are an infinite number of positions that a unit can occupy), and it's close to that in modern video games, but not really.  Still, it is nearly continuous.  To counter this and simplify the problem, the game's programmers will discretize (approximate) the map.  The most common way of doing this is to introduce &quot;nodes&quot; on the map.</p>
<p>A chess board is &quot;discrete,&quot; in that a piece must be on a square or off of it.  A piece can't be half-on/half-off, it can't be a quarter on/quarter off, and it can't be 3.14159265359... on a square.  Nodes take a continuous space and approximate positions on the map into discrete locations.  Obviously, the more nodes, the more realistic the approximation will be, but the computation will be more complex.  Ideally, the nodes will be distributed evenly.  At this point, the programmer can compute every path from every node to every other node, and on a modern computer, this won't take <em>too</em> long, but what if the terrain changes or a unit is in the way?  This is where the A* algorithm (pronounced &quot;A Star,&quot; which makes it very difficult to Google) comes in.</p>
<p>A* is a very powerful algorithm that falls into the family of &quot;informed search.&quot;  An uninformed search algorithm will naively search every every possible outcome.  An informed search will use information from the current step to assess how good the solution is and make decisions based on that information.  This information is what is known as a &quot;<a href="http://en.wikipedia.org/wiki/Admissible_heuristic" target="_blank">heuristic</a>.&quot;  A heuristic is an educated guess about how far away the solution is from a given state.  If the heuristic is admissible (tl;dr/ELI5: &quot;good&quot;), the solution is guaranteed to be optimal.  An admissible heuristic for pathfinding is usually <a href="http://en.wiktionary.org/wiki/Manhattan_distance" target="_blank">Manhattan Distance</a>.</p>
<p>So let's dial it back for a second.  You're a unit, you know where you are, you know where you want to go, and you know what possible moves you can make from your current position.  You look at all of your possible next positions and rank them based on your heuristic.  Then, you take the best option from that list, compute all the possible moves from THAT position, rank them by heuristic, repeat.  If you run into a dead end, you go back to the previous list you generated and pick the second best option, and so forth.  Once you've found the best path, you take it.</p>
<p><a href="http://i.imgur.com/mlSpcXw.gif" target="_blank">Here</a> is a visualization (taken from the <a href="http://en.wikipedia.org/wiki/A*_search_algorithm" target="_blank">Wikipedia article on A*</a>) of the algorithm in action.</p>
<p>This is a powerful algorithm because it can be used for more than just pathfinding.  Any problem that can be made into a graph can usually be solved optimally with A*.</p>
<p><strong>Decision-making:</strong>  Any turn-based game will have decisions made each turn, but for a simple example, let's use tic-tac-toe.  Let's imagine an &quot;agent&quot; (artificial intelligence) playing the game at the outset as the &quot;x&quot; player.  At the beginning of the game, the agent has 9 options of where to place the first x.  Similar to A*, the agent can compute all 9 possible moves and how likely they are to garner a victory just based on the position of the first x alone.  The agent still needs a heuristic here, so it should probably value 3 x's in a row very highly, 2 x's in a row with two open spaces to complete the row/column/diagonal almost as highly, and perhaps give value to a single x in a given valuable square.  Now the agent has to consider the &quot;o&quot; player's turn.  For a good decision-making agent, it should assume the &quot;o&quot; player wants to make its decision based on what will be worst for the &quot;x&quot; player, so it should calculate all 8 possible placements of the &quot;o,&quot; decide which is worst for the &quot;x&quot; player, and assume it will make that move.  From here, the agent should calculate all 7 possible &quot;x&quot; placements, rate them, continue.</p>
<p>The astute reader should see at this point that the depth (in this case, how many turns) of this game and it's state space is 9 as there are only 9 spaces.  From the first turn, the first agent has 9 options, and every subsequent turn has one fewer, but in computer science, we care about the worst case, so that means that there is a &quot;branching factor&quot; (number of choices) of 9, and a depth of 9, giving 9^9, or 387,420,489, possible ways the game can play out (please check my math, again, early morning, hungover).  That sounds like a big number, but to a modern computer can handle that easily.  This means that it is possible to &quot;solve&quot; tic-tac-toe.  In this case &quot;solve&quot; means come up with a strategy that will always win/tie/play optimally given that the agent has the first move.  Most games are far more complex.  Consider a turn-based game like Civ5.  There is a huge number of options a player may choose each turn.  The number of options will determine your &quot;branching factor.&quot;  More on this later.</p>
<p>Consider chess.  In 1996, an AI chess-playing agent called <a href="http://en.wikipedia.org/wiki/Deep_Blue_%28chess_computer%29" target="_blank">Deep Blue</a> beat chess world champion and grandmaster <a href="http://en.wikipedia.org/wiki/Garry_Kasparov" target="_blank">Garry Kasparov</a> in Philadelphia (where I am right now, actually).  This is significant for a number of reasons.  For one, the movie <em>2001: A Space Odyssey</em> had a scene where Hal, the <em>Discovery's</em> AI, beats one of the astronauts in chess, and when I saw that movie for the first time (circa 2005), I didn't think twice about it, but in 1968 when the movie came out, this would have been a very sci-fi fantastical concept.  It's also significant because, while chess is almost sure to have a dominant strategy, it is not &quot;solved;&quot; the dominant strategy is not known.  The space-complexity of the game is also far more complex than tic-tac-toe, and that game had (on the order of) 387,420,489 ways in which it can play out.  Furthermore, the depth (number of turns) is potentially infinite, because it would be a legal move to have a rook move back and forth between two spaces indefinitely.  Exploring every single state and every single decision would be a HUGE computational burden, even for a modern computer.  A single knight has 8 possible spaces to which it can move (given that they are not occupied by one of the agent's own pieces or off the board), and the player has two of them.  A rook in a corner can move to 14 different spaces.  Any pawn can move on the first turn (or knight).  While I am not sure how &quot;Deep Blue&quot; handles this, my guess is that it uses some kind of &quot;Monte-Carlo&quot; approximation, in which it randomly selects a strict-subset (some but not all) of possible moves and explores the results of those rather than all of them.  The more states in your subset, the better your approximation, but this comes at the expense of computation time/resources.  This could be its own topic and I'm running out of characters, so I'll move on.</p>
<p>The definitive textbook on AI is Russel and Norvig's &quot;AI: A Modern Approach.&quot;  The cover of the book shows the final configuration of the chessboard when Deep Blue beat Kasparov with relevant pictures on the squares, including Alan Turing (if you haven't seen <em>The Imitation Game,</em> oh my God go see it even if you aren't a math/computer science person).</p>
<p><a href="http://i.imgur.com/UjU1Pmi.jpg" target="_blank">Here's the cover</a>.</p>
<p><strong>Drama Management:</strong> If you play Left4Dead, you've seen this one.  Have you noticed that if you're progressing quickly, the game starts throwing more and increasingly difficult enemies at you?  An AI is behind that.  This is so good players and bad players can enjoy the game equally.  If you are doing poorly, it goes easy on you.  If you're doing well, it gets harder.</p>
<p>I don't know this for a fact, but I strongly suspect that &quot;The Last of Us&quot; uses a simple drama management agent to control how much ammo you have.  I've noticed that you never feel like you have a safe amount of ammo.  If you're out, you always find some, but you never seem to have a surplus. (con't)</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<a class="less-answers upper" href="javascript:void(0)">less answers...</a>
	<div class="answer" data-handle="cncyf5p">
		<a class="author" href="https://www.reddit.com/user/Xinhuan" target="_blank">Xinhuan</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>This really depends on what type of video game it is (genre).</p>
<p>The most important thing about AIs is their behavior should be believable, an AI that takes 20 seconds to calculate the best action for a monster to move in a First Person Shooter would not be believable. AIs in such games usually use some sort of flow chart that is quick to follow (which is essentially a series of If Thens), but more advanced ones use Finite State Machines (FSM) along with flow charts. For example, a monster could be in Idle state, there is a condition it will check for to enter the Alert state, and on visual line of sight, the monster could enter Combat state. Behavior (aggressive vs defensive) could be coded by weighting different options differently (calculate a &quot;score&quot; for advancing, vs ducking behind nearest cover position) and picking the option with higher score. Even more advanced monsters could use group tactics (flanking, cover fire, etc).</p>
<p>For turn based games, these types of games often follow very fixed and known rules, with a limited number of moves available to players on each turn. Examples such as Chess, card games, etc. Some simpler games can Brute force and calculate out every possible move for the next X moves and scoring the outcome of the playing field based on a formula, the best ones prune entire decision trees as being completely worse off by using a technique called Alpha-Beta Pruning. Storing results of previous calculations in memory help improve speed, or even storing databases of them on disk (eg, chess opening books). To prevent taking forever on calculating a move, these is typically a time limit where it stops looking for a better move after some time and just uses the best move found. Scrabble AIs tends to just brute force a single move, since it cannot really predict what the other players have in their hands - strategy will vary whether players have all the information available (checkers), or if some information is hidden (eg poker hands).</p>
<p>But there are also advanced turn based games like Civilization, or complicated games like Starcraft. These types typically use an AI called the Blackboard AI, which uses sub-AIs. So there is a &quot;Economics AI&quot; that says &quot;we need more minerals&quot;, and a &quot;Tech Tree AI&quot; that says &quot;we should research this tech&quot;, and a &quot;Exploration AI&quot; that says we need to see what's over here (more than any other location), etc, or a &quot;Relations AI&quot; that thinks we need to improve relations with this neighbour, and a &quot;War AI&quot; that says we should move these units here and there. All these subsystems feedback to an overall master AI called the Blackboard that takes in all these requests, and then figures out how to allocate a finite amount of resources to a large amount of requests, by ranking each request based on how important it thinks that request is (how early the game is, stone age, modern age, number of bases/cities etc, importance of a location). These types of AIs are the <em>hardest</em> to balance since scoring each request is really just based on arbitrary formulas, modified by the &quot;aggressiveness&quot; setting of that AI or the difficulty level of the game.</p>
<p>It is also important to know some AIs perform great because they cheat. In some games, the computer AI knew exactly where your army was, even though in theory the AI shouldn't know this due to fog of war. Starcraft is guilty of this, but Starcraft 2 made a genuine effort not to cheat. Civilization &quot;cheats&quot; by increasing the rate of production/resource gathering on higher difficulty levels for the AI. The &quot;Insane AI&quot; on Starcraft 1 gains 7 minerals instead of 5 per trip.</p>
<p>Some &quot;AIs&quot; aren't even AIs at all. Level X of this campaign in Starcraft might seem intelligent, but all it is doing is just following a designer script that says &quot;spawn this set of units every 5 minutes and throw it at the player&quot; and &quot;15 minutes into the level, spawn this set of units and attack from the backdoor&quot;. Still, if scripting specific events and narrative into a game results in good gameplay, then that is probably ok.</p>
<p>Look at say the classic Super Mario, the Goombas simply walk in one direction, can fall off ledges and turn around if they bump into a wall. Turtles behave exactly the same, but don't fall off ledges. They still qualify as AI, it just isn't particularly smart, since such AIs are extremely simple If-Thens; that doesn't mean the game is bad, simple AIs lead to predictable monster behavior that the player can take advantage of (eg, timing Mario's jumps at the right time). Most monsters in Diablo just make a straight beeline for you, a few might flee away on low health, but they are predictable. With that many monsters in a level, it is important to make every monster have AIs that perform very quickly, most monsters only run their AI once every 0.5 seconds, or even every few seconds, rather than recalculate every frame. This also leads to believability, no humans react instantaneously, neither should AI.</p>
<p>Minecraft used to have very simple monster AIs, the zombies and creepers just make a beeline for you, often falling into pits in the way, or just running into that tree trunk on the way. It was patched a few years later to have actual pathfinding (the Pigmen still have original beeline AI). While this was great on single player, this became very problematic on large servers with a lot of areas loaded in memory - the servers slowed to a crawl because there were large amounts of monsters spawning across the loaded areas, running a lot of pathfinding where in the past, it was just running in a direction towards the player. Some servers opted to mod their servers and have the monsters go back to the simplified beeline AI to reduce server load.</p>
<p>TLDR: Different games require different kinds of AI. What comes down to whether an AI is considered good or terrible simply boils down to whether it made a choice/move that is <strong>believable</strong> to the player, and there are computation constraints to calculating the best move.</p>
<p>Edit: Added a paragraph on cheating AIs, designer scripted AIs, and another on Minecraft.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="cncyrpq">
		<a class="author" href="https://www.reddit.com/user/CyberBill" target="_blank">CyberBill</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>Actual professional game developer here!</p>
<p>Every game has it's own AI implementation that could be something incredibly simple, or something incredibly complex, and the outcome (how much the player likes the game's AI) is pretty much unrelated to how well it plays the game.  It's much more of a game design mechanic that has to be tweaked and played with than it is something that can be solved.</p>
<p>Let me give you some examples using a game I worked on about ten years ago.</p>
<p>It was a game in the style of &quot;Worms&quot; or &quot;Scorched Earth&quot;.  Our AI implementation for months was about 3 lines of code that chose a random weapon, a random angle, and a random 'power', and shot.  It felt surprisingly good, as sometimes it would just blow itself up, and sometimes it would hit you dead on from across the map.</p>
<p>Once we had most of the game play done, we had an AI guy whose entire job was to write a really good AI.  It went through the list of all enemies, calculated an exactly correct trajectory derived using the same algorithms that we used for the physics engine, and then determined which weapon to use that could potentially harm more than one enemy - basically it optimized for doing the most damage, and it was perfectly accurate every shot.  It made the game absolutely horrible and unplayable because you would lose every single game.</p>
<p>After that, we added a bunch of adjustment values that would randomize the trajectory and stuff, to make it less likely to hit the target.  It made it feel MUCH better.  This actually turns out to be how a LOT of AI is made - for instance Quake III AI enemies inherently are 100% accurate.  They make a seemingly perfect AI, and then dumb it down until it's actually fun.</p>
<p>Depending on the game, a lot of AI will use a state machine to set itself to be 'defending', or 'attacking', or 'sneaking', or whatever.  This turns out to be pretty close to a long series of 'if then' statements.  However, the actual statements that determine actions (such as changing state) may be implemented as &quot;fuzzy logic&quot;, which is just another way of saying that we take a bunch of weighed values and throw in a randomness factor.  You'll also see the term &quot;neural network&quot; used in relation to AI, and some really high-end games may use machine learning to optimize the AI logic values.</p>
<ul>
<li>Edit -
For anyone interested, I've uploaded the game (including source) here:
<a href="http://letsmakegames.com/Rekoil.zip" target="_blank">http://letsmakegames.com/Rekoil.zip</a></li>
</ul></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="cnd13q1">
		<a class="author" href="https://www.reddit.com/user/nashvortex" target="_blank">nashvortex</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>All AI can be explained as follows : </p>
<ol>
<li>
<p>There is a list of valid actions for the AI. These may be 'cheats' in the sense that a player may not have the same valid actions. An example would be that a player has to choose what unit from the barracks before creation timer begins, while the AI can simply choose to create an undefined unit and choose after the timer is over what the unit should be. There are several more examples.</p>
</li>
<li>
<p>There is a set of information available to the AI. Again, this can include 'cheats' such as knowing what the player's unit composition is without vision etc.</p>
</li>
<li>The objective - The objective of the AI is to ensure that a player's game parameters remain within a certain set of limits, by using the actions available to it. So for example, if the player is getting too many resources, the AI will notice it and then attempt to use its units to destroy resource harvesters etc. These naturally vary from game to game. At its root, this is a [non-linear optimization problem] (<a href="http://en.wikipedia.org/wiki/Nonlinear_programming" target="_blank">http://en.wikipedia.org/wiki/Nonlinear_programming</a>). There is a certain range of time, resources, units , progression that the game developers think will lead to a good 'player experience'. The AI therefore responds to the players actions with its own actions to try and adjust these parameters to stay within the allowed limits.</li>
</ol>
<p>Now, there are many methods to perform non-linear optimization : One way is to use many many if-then statements, like  you mentioned. This can get very inefficient except for the most simpest of actions. </p>
<p>Another way, is to use a graph which shows how a certain parameter should develop over time, or a graph that correlates two parameters. There is an 'ideal' graph that the developers have already given the AI and the AI tries to do whatever it takes such that the actual development of this parameter in a game matches the ideal graph as closely as possible. </p>
<p>Practically, all games use some sort of mixture of these various methods. You can see now that what makes an AI good or bad is how efficiently and cleverly it utilizes the information available to it and how quickly and appropriately it is designed to respond to the various situations in a given game. </p>
<p>Some of it is also a subjective opinion, for example, you may simply not like the limits and responses the developer decided makes for a 'good' player experience based on their surveys and beta testing. This is not technically bad AI, its a case of bad (for you) developer decisions that gets rammed on the AI.</p>
<p>I know, you cannot mention non-linear optimization and expect it to be ELI5. But what the hell, 5-year olds are a really bad bar for explanation anyway.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="cnd1buc">
		<a class="author" href="https://www.reddit.com/user/kaeles" target="_blank">kaeles</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>This is a big pastime of mine.</p>
<p>So, AI is really just responding to the environment that the agent finds itself in.</p>
<p>How do we map the environment?  What are an agents &quot;senses&quot; in a game?</p>
<p>A lot of times, developers will use either a walk-mesh, or navmesh.  Some tools allow you to automatically compute these (I'm looking at you recast).
<a href="http://cotdp.com/wp-content/uploads/2011/06/RedcastDemo_Northshire_Abbey1.png" target="_blank">example navmesh</a></p>
<p>Now that we have a mesh that represents the places you can walk, we need to learn how to navigate around this mesh.  Imagine each triangle in the mesh a has a point at the center, we will call this the centroid.</p>
<p>Now imagine that each centroid of each neighboring triangle is connected with a line.  This set of centers and connections are turned into a &quot;graph&quot;, which is a fancy term for connected dots. This looks something like <a href="http://tkfiles.storage.msn.com/x1pC-7nLWDVofRk3ks1q_3zDuQc3pIvbYBRYZ81Ni5K0Qdtg_daLJB9NOd0Xh5y-mJLxXKqPSeOFUu36wUQqstdWhI7XU8Lfd5kAtZUPabX_LUqPR64pelNLH7hQizDssot_r1W84GCFy0" target="_blank">this</a>.</p>
<p>Now we can use an algorithm to find the shortest path between two points on the navmesh using this centroid graph. The numbers on the lines or &quot;edges&quot; represent the &quot;weight&quot; of that edge, or for navigation, how far it is, or more generally how much it costs to move there, if say ladders are slower to climb, you may want to cut around them.</p>
<p>So, now that we can find our way around the map, you can decorate that navmesh with some nice information about cover and etc, or update it if objects get dropped in the way.</p>
<p>Finally, now we can move around (yaaay), you can use some <a href="http://red3d.com/cwr/steer/" target="_blank">steering behaviors</a> to make the movements between the waypoints look a little more natural.</p>
<p>Now, how do we decide where to move (sure we can navigate there but WHY?), how do we plan actions and then execute them?</p>
<p>Couple of ways, one is FSM or finite state machines, this has been explained in this thread many times.  Quake 3 used these.</p>
<p>So other ways, Behavior Trees are a very very popular thing right now, they are basically a really fancy FSM that makes the transitioning between states waaaaaaaaaaaaaaay simpler and easier to keep track of.  I would check these out.</p>
<p>Another way is something like GOAP (goal oriented action planning) where there are a set of actions available that have pre and post conditions, and there are a set of goals.  You turn this into a graph and navigate along it the same way you do with the graph for navigating around the map.  The AI in FEAR used this technique.</p>
<p>This allows you to find the &quot;shortest path&quot; through the action/goal solution space to the desired goal.</p>
<p>You just save that &quot;path&quot; as the set of actions to execute, and then execute the actions one at a time.</p>
<p>Some books on this topic are AI Programming by example (matt buckland).</p>
<p>You can look at my half done <a href="https://github.com/vantreeseba/de.steer.js/blob/master/src/behaviors/behaviors.js" target="_blank">steering library</a> on github to see how easy some of the steering code is (seeking a point or enemy is 1 line).</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
</div>