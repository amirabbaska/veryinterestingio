<li class="post" data-handle="762d05">
	<div class="overview">
		<a class="source" href="https://www.reddit.com/r/explainlikeimfive/comments/762d05/eli5_ai_was_never_shown_what_walking_looked_like/" target="_blank" title="Reddit thread where this comes from"><i class="fa fa-external-link" aria-hidden="true"></i></a>
		<h2>
			<span class="tags tag-Technology">Technology</span>
			<a href="/posts/762d05" onclick="return false">A.I. &quot;was never shown what walking looked like&quot; and yet &quot;taught itself to walk&quot;</a>
		</h2>
		<!--<span class="date">2017-10-16</span>-->
		<span class="is-new">NEW</span>
	</div>

		<div class="question"><span class="qa" title="Question">Q:</span><div class="markdown"><p><a href="https://gfycat.com/FirsthandUniformArchaeopteryx" target="_blank">This animation of an AI &quot;learning&quot; to walk.</a></p>
<ul>
<li>
<p>What does it mean that the AI was &quot;never shown what walking looks like&quot;.  Wouldn't the programmers have to provide a finite number of possible configurations of parts, or simple limitations, which would effectively feed the AI the answer to &quot;this is walking&quot;?</p>
</li>
<li>What does it mean to &quot;incentivise&quot; AI?  Is that an attempt to anthropomorphize the act of giving instruction?  Is it actually an incentive for the AI, like a cookie is an incentive for a toddler?  Or is it just a command?</li>
</ul></div></div>

	<div class="comment-section">
		<div class="answers-placeholder">
			<div class="answers">
	<div class="answer" data-handle="doatftd">
		<a class="author" href="https://www.reddit.com/user/Koooooj" target="_blank">Koooooj</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>The programmers start by setting up an environment--some sort of basic physics engine, much like you might find in a modern game.  Within this engine, they design the physical structure of the model that they want to walk--it gets arms and legs, with physical properties like strength and inertia.</p>
<p>From there the AI's job is to take some information about the state of the model and use that to come up with how hard it should pull or push each joint.</p>
<p>To say that the AI wasn't &quot;shown how to walk&quot; this means that the programmers didn't go in and say &quot;walking consists of moving legs back and forth, alternating, while swinging your arms back and forth.&quot;  A traditional approach would start from some basic motion profile like this, then let the AI learn how to tweak that profile in response to what simulated robot senses.  This AI was given no such starting point and it's likely that the first approaches looked more like seizures and first-time player of QWOP than anything remotely resembling walking.</p>
<p>The incentives come into play as the AI learns.  Many AI approaches consist of trying different things, measuring which ones performed best, then tweaking the best performing options.  For this kind of approach you need some way to identify something as &quot;best.&quot;  For these AIs this seems to have been a simple distance measurement.</p>
<p>To see something similar done you should check out www.boxcar2d.com.  To draw parallels, this AI seeks to build a car with no idea what cars look like, with the incentive of traveling to the right on the screen. At first the guesses are horribly mangled garbage, but after a few generations they start to look remarkably car shaped and they start managing to cover an impressive distance. </p></div>		<div class="replies-placeholder"></div>
	</div>
	<a class="less-answers upper" href="javascript:void(0)">less answers...</a>
	<div class="answer" data-handle="doat19l">
		<a class="author" href="https://www.reddit.com/user/TokyoJokeyo" target="_blank">TokyoJokeyo</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><blockquote>
<p>What does it mean that the AI was &quot;never shown what walking looks like&quot;.</p>
</blockquote>
<p>There's a model with parts that are attached with some simulated physics. That constrains what the part can do. The AI program is in charge of providing the input--how will the parts move? At first, it's input is simply random. For example, the input to each leg may not be synchronized in any way.</p>
<blockquote>
<p>What does it mean to &quot;incentivise&quot; AI?</p>
</blockquote>
<p>For each run, the program stores what it does and whether it fails or succeeds. (It probably stores how far it got to the end point, too, and how long it took.) The next time it runs, it repeats actions correlated with success and avoids actions correlated with failure. Over time, its actions become less random as, by chance, it finds successful things to do and keeps doing those. Note that movements not strongly tied to either success or failure stay mostly random, e.g. look at the flailing of the arms.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="dob3tl4">
		<a class="author" href="https://www.reddit.com/user/Em3rgency" target="_blank">Em3rgency</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><ol>
<li>
<p>The AI was never given to goal of &quot;Learn to walk&quot;. It was given an environment and a puppet to control with the goal of &quot;Get puppet over there&quot;. The AI then eventually came up with walking as a propulsion method.</p>
</li>
<li>It was not given instructions on how to achieve the goal. It was shown what the current state is, what the possible interactions are (muscle contractions on the puppet) and what the goal is. The closer it gets to the goal, the better score it gets. So you could look at it this way - its instruction was to get the best score possible. And since getting closer to the goal increased the score, it was incentivised to get to the goal.</li>
</ol></div>		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="doaz9er">
		<a class="author" href="https://www.reddit.com/user/TBNecksnapper" target="_blank">TBNecksnapper</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><blockquote>
<p>Wouldn't the programmers have to provide a finite number of possible configurations of parts, or simple limitations, </p>
</blockquote>
<p>they don't need to possible provide configurations, just possible actions, the AI has to figure out how to combine the actions itself. Yes limitations on actions would be provided.</p>
<blockquote>
<p>which would effectively feed the AI the answer to &quot;this is walking&quot;?</p>
</blockquote>
<p>No, there are many ways to try to get moving that are not walking, the AI was not rewarded based on how close to walking it moved, but how successfully it moved in general. If there is a more efficient way to move forward the AI could very well have found that instead of walking.</p></div>		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="doato8t">
		<a class="author" href="https://www.reddit.com/user/friend1949" target="_blank">friend1949</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>Remember this is a simulation. There is no true landscape. There is no creature running.</p>
<p>The programmers wrote a program which created a landscape. They wrote a program to resemble a final creature. What liberties they took we do not know. Apparently the creature gets some sort of &quot;sight&quot; in that objects ahead can be detected so that eventually it could walk around objects.</p>
<p>Now come the interesting part. The programmers designed some sort of mutation effect. The program generating the creature would change itself randomly. We do not know what parameters the designers allowed mutations on. But multiple variations of the original creature could be generated.</p>
<p>The designers now had mutated creatures in a landscape. They ran innumerable iterations of mutated creatures. When random mutations in the   program creating the creature produced one which could move  that program as selected and preserved. Ir was reused as the creature basic program. More mutations were created. the ones which moved best were selected for. </p>
<p>With millions, maybe billions or more, of iterations of this selection process the animation which walked the best was produced. </p></div>		<div class="replies-placeholder"></div>
	</div>
</div>		</div>
		<div class="more-less">
			<a class="collapse" href="javascript:void(0)">collapse</a>
			<a class="more-answers" href="javascript:void(0)">4 more answers...</a>
			<a class="less-answers lower" href="javascript:void(0)">less answers...</a>
			&nbsp;
		</div>
	</div>
	<a class="show" href="/posts/762d05" onclick="return false"><span>show</span></a>
</li>
