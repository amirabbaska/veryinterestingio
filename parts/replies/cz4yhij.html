	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><blockquote>
<p>Comes out to about 100uJ/bit. Or really nothing.</p>
</blockquote>
<p>That's extremely far from nothing (and reality). 100 ÂµJ/bit when transferring just 8 Mbps would mean the router is pulling 800 W.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/supermeandyou" target="_blank">supermeandyou</a>
			<div class="markdown"><p>The router is sending and receiving data all the time even when you are not using it, actually going on the internet and sending data makes absolutely no difference to the router other than the stream of data changing. you can use the full bandwidth of your router or just a little bit of it and it ill cost you exactly the same in power consumption.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><p>It will (give or take) cost the same in energy per unit of time, but not in energy per unit of data as you calculated.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/clavicon" target="_blank">clavicon</a>
			<div class="markdown"><p>This doesn't make sense to me. Can you explain? If you have a computer making no requests at all plugged up to a router, which plugs up to the cable modem, and on to the net, how is this drawing less energy than when you are downloading packets at 10 MB/s, for example?</p>
<p>Is the router constantly sending &quot;NO DATA&quot; at full throttle? Even this doesn't make sense to me. Doesn't the router have its own memory chips and CPU with resistors that have to be switched between 0 and 1, and that's where energy consumption mostly comes from?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ewand" target="_blank">ewand</a>
			<div class="markdown"><p>I didn't specify an important detail, but it is covered in other comments and in the links I provided. The energy use changes little with use. If you use 2GB a day, then your energy per bit is cut (essentially) in half. This is imperfect, but I'm using one significant figure. Observed Internet access patterns are sporadic rather than constant. Sure, there are exceptions, but the general case is that energy goes down as utilization increases. And this is because utilization is, at best, a 2nd order contributor to energy use. </p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/IAmA_Catgirl_AMA" target="_blank">IAmA_Catgirl_AMA</a>
			<div class="markdown"><p>Assuming a max size packet (Because the other guy did that) I get 6.5 Joule/Packet.</p>
<p>That's way more than /u/VirtualMachine0's estimate. I wonder which one is more accurate and where that difference stems from.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/VirtualMachine0" target="_blank">VirtualMachine0</a>
			<div class="markdown"><p>6.5 is surely more accurate. The difference is mainly in my use of home routers and underestimating the number of nodes.</p></div>		</li>
					</ul>
		</ul>
	