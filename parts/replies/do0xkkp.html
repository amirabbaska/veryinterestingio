	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/usernamelimitsaredum" target="_blank">usernamelimitsaredum</a>
			<div class="markdown"><p>This should be higher up. Even if a 1 has more mass than a 0 or vice versa, memory being more or less full doesn't mean that it will weigh more or less. A phone with 0GB used could have more 1s than a phone with 60GB used.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/darkslide3000" target="_blank">darkslide3000</a>
			<div class="markdown"><p>Everybody in this thread is saying this and it's not really true for flash storage. Most operating systems today make use of <a href="https://en.wikipedia.org/wiki/Trim_\(computing\)" target="_blank">TRIM commands</a> to tell the storage device which sectors are empty and should be erased in the background at the next best opportunity (i.e. when the device is otherwise idle). This is because erasing flash blocks takes significantly more time than writing an already erased block, so getting it out of the way ahead of time is useful to get faster write speeds later.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/3058248" target="_blank">3058248</a>
			<div class="markdown"><p>Structured information (data) has a lower entropy than unstructured information. Are there any entropy-mass relationships?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Timwi" target="_blank">Timwi</a>
			<div class="markdown"><p>This is only true of uncompressed data. Good data compression puts the data in an arrangement statistically indistinguishable from randomness. Any place where entropy is still low is a candidate for further compression.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/pick_me_apart" target="_blank">pick_me_apart</a>
			<div class="markdown"><p>This sounds somewhat intuitive but is there a source you can recommend that explains this in more detail?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Dhaeron" target="_blank">Dhaeron</a>
			<div class="markdown"><p>Data entropy has the same name but otherwise not much to do with physical entropy. </p></div>		</li>
					</ul>
		</ul>
	