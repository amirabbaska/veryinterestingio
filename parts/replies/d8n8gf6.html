	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/fredrikj" target="_blank">fredrikj</a>
			<div class="markdown"><p>The BBP algorithm still requires O(log(n)) memory, so that's technically wrong. It just so happens that log n is nearly constant in practice.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Teblefer" target="_blank">Teblefer</a>
			<div class="markdown"><p>Using all the processing power of the whole observable universe, what nth digit of pi could we never get?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/lolzfeminism" target="_blank">lolzfeminism</a>
			<div class="markdown"><p>I mean, it depends on how many bits you can store per atom. There are ~10^80 atoms in the universe.</p>
<p>If we're very conservative and say 1 bit per atom, then we can get to  ~10^160 .</p>
<p>Theoretically because each quantum bit or qubit can be in a super-position of 0 or 1, the state of an n-qubit quantum computer describes a 2^n - 1 bit value. That means if you constructed a quantum computer from the entire universe, you would have 2^10^80 bits of memory. Square that because of O(log n) and we get to  2^10^160 ~ 10^10^159 digits of Pi . That's 60 orders larger than a googolplex. </p>
<p>And there's more than one way to make a qubit using an atom. </p>
<p>Nothing about what I'm saying is theoretically wrong, but it's also pointless.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MakingMarconi" target="_blank">MakingMarconi</a>
			<div class="markdown"><p>/u/whatsthepoint--- gave a pretty decent proof by contradiction in another top level comment. These spigot algorithms may compute pi one digit at a time but their space complexity isn't O(1). I mean... consider even the counter in a spigot algorithm. You have to know when to stop running the algorithm, right? So you'll need some number, <code>i</code>, which increments for each loop until you get to the digit you want. Make the input (<code>n</code>) large enough and <code>i</code> alone will take up 1MB of space before it gets to <code>n</code>.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/aclay81" target="_blank">aclay81</a>
			<div class="markdown"><p>Does it require unbounded memory beyond the ability to store n?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ribnag" target="_blank">ribnag</a>
			<div class="markdown"><p>It does take a few other items of similar size, so overall still fits into O(log(n)) space, but as others rightly pointed out, O(log(n)) isn't O(1).</p>
<p>In practice, this is a case where &quot;640k is enough for anyone&quot;, because you start getting into huge multiples of the age of the universe to actually run the program before you'd exhaust even that tiny amount of memory.  But, the OP didn't ask about a practical answer, s/he phrased it strictly as a theoretical - So my original answer is very definitely wrong.</p>
<p>You start getting into some weird computational situations when log(n) grows big enough to matter.  :)</p></div>		</li>
					</ul>
		</ul>
	