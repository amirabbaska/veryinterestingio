	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/will_owens18" target="_blank">will_owens18</a>
			<div class="markdown"><p>Woah. That's cool.</p>
<blockquote>
<p>The only way that we could define a <em>truly random</em> string is to write down the string itself; if there were a (deterministic) program that could produce it for us, then the string is no longer truly random by definition. So if we'd like a &quot;random number generator&quot; program to generate random numbers on demand, it would have to be able to generate an infinite number of random numbers. And because the Kolmogorov complexity of this infinite string of numbers is as long as the string itself, the program would need to take up infinite space.</p>
</blockquote>
<p>A great show of how nothing is truly random. To be truly random is to not be able to define it with a function. Every random number is made with a function and therefore cannot, by definition, be random.</p>
<p>Do you think there are programs that reverse engineer random numbers and the formulas used?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/kpl12" target="_blank">kpl12</a>
			<div class="markdown"><blockquote>
<p>A great show of how nothing is truly random. To be truly random is to not be able to define it with a function. Every random number is made with a function and therefore cannot, by definition, be random.</p>
</blockquote>
<p>At risk of this going beyond ELI5 ... one of the basic properties of the Kolmogorov complexity is that it's bounded from <em>above</em> by the size of the string itself plus some constant number. And that's basically just a formal way to say, any string <em>s</em> can be generated by a program that basically says &quot;print s&quot;. So, to be completely pedantic, something that is truly random can be defined by exactly one function, which is precisely the function that is of the sort &quot;print s&quot;.</p>
<blockquote>
<p>Do you think there are programs that reverse engineer random numbers and the formulas used?</p>
</blockquote>
<p>Certainly! For some of the &quot;less good&quot; RNGs, often simple statistical analysis will reveal patterns. On the <a href="https://www.random.org/analysis/" target="_blank">random.org analysis</a> you can see a visualization of &quot;good&quot; versus &quot;bad&quot; randomness. For something that's extremely mathematically dense, but shows the importance of a good RNG and the difficulty of creating one, <a href="https://en.wikipedia.org/wiki/Dual_EC_DRBG" target="_blank">here's</a> an interesting read about a backdoor that the NSA put into a RNG used in cryptography.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/will_owens18" target="_blank">will_owens18</a>
			<div class="markdown"><p>Thanks so much for the response. Lots of great info here.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/myexisproblematic" target="_blank">myexisproblematic</a>
			<div class="markdown"><p>I know someone who's thesis is about parametrizing PRNG's (PseudoRandom Number Generators) and creating solution methods for them. </p>
<p>Their current work is on breaking down large periodic behaviours into related smaller periodic behaviours, then using enough inputs from the PRNG.</p>
<p>So if I was generating a number between 1 and 4, I could make the sequence A= 1,2,3,4 and then nest it on itself: Shift(A,1),Shift(A,2),Shift(A,3),Shift(A,4) = 1,2,3,4,2,3,4,1,3,4,1,2,4,1,2,3</p>
<p>In this case, it's easy to see that the general pattern is &quot;add 1&quot;, but harder to see why sometimes it'll up or down by more than that.</p>
<p>If you want a reasonable chance of predicting the next number though, knowing that you need to add 1 is enough. It would work for 9 of the 16 inputs in the sequence above, which would not only be more than the 25% of guessing randomly, it's the majority of times. </p>
<p>Their thesis asserts something like, (not my field, not my thesis), that every PRNG that has a period longer than the quadratic of its seed number exhibits significant sub-periodic behaviour like this that can be used to predict with higher than random accuracy the next number in a PRNG sequence, which allows parametrizing the PRNG much faster than needing to know the state of the system. Wait, that sounds wrong. It allows creation of paramaterizations that get close to the number sequence long before you actually know the state of the machine. Maybe. </p>
<p>So it follows down the line of Marsaglia and all that jazz. They got interested in the idea a decade and a half ago when they were making a computer game and they happened to line up their map with the limitations of the mersenne twister PRNG that their programming language used. It was something like 72x55 tiles of 7 types each, (not actual numbers) and whatever it was, it was perfect to create near identical structures when used to generate multiple maps in a row. Not identical structures, but near identical ones. </p>
<p>Long answer short, check out some of Marsaglia's work and the papers on the topic since then if you ever want an academic overview of PRNG parametrization. </p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/barsoap" target="_blank">barsoap</a>
			<div class="markdown"><blockquote>
<p>while there is no &quot;compact&quot; way to describe the second</p>
</blockquote>
<p>Nitpick: That you know of. It could very well be that it's possible to compress a lot with an sufficiently smart algorithm.</p>
<p>This is the very point: Just because <em>you</em> can't easily predict the next bit in the sequence doesn't mean that it's actually random, a very good example here is <a href="http://encode.ru/threads/1211-Compressing-pi" target="_blank">a zpaq scheme to compress the first milion digits of pi to 126 bytes</a>. That  special configuration file there is not necessary to extract the archive, only to get zpaq to compress the digits that well (the &quot;sufficiently smart&quot; part).</p>
<p>Imagine we would be broadcasting digits of pi out into the universe, and a super-intelligent and advanced species picked it up. Chances are overwhelming that they'd think we're nuts because who the fuck would broadcast random data: Even with a well-known number like pi, figuring out that it's digits of pi when you missed the beginning isn't that easy, it's completely indistinguishable -- statistically speaking -- from absolute randomness.</p>
<p>Yet, evidently, quite compressible.</p>
<p>Which is why there's different notions of entropy and information: The theoretically-minded ones like Kolmogorov get into trouble for any string -- even small ones -- because to make sure that it's actually not compressible, we have to do a brute force search over all programs that are smaller than the string, to see if none of them produce the string.</p>
<p>And that involves solving the halting problem for those programs, as they might indeed not halt before outputting the first bit that you could compare to the desired output string.</p>
<p>Slightly restricted versions, are, of course, possible: Just use a decidable language.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/DSMan195276" target="_blank">DSMan195276</a>
			<div class="markdown"><p>To go along with this, if you're stuck on the idea of &quot;smallest program required to produce&quot;, that's really just a fancy way to describe compression (For the most part). Compression requires recognizing patterns in the input, and then rebuilding the data later based on those patterns. &quot;abc 10 times&quot; is a compressed version of 'String 1', because it requires less data to store then the original but can still be use to perfectly recreate the original. Things like <code>zip</code> files work this way (Obviously it's more complicated then that, but finding patterns is the basic idea).</p>
<p>Random data contains no patterns - that in many ways is a simplified definition of random. Because of this property, it is (generally) not compressible - because compressing it would require finding patterns, which it doesn't have. The more random data you have, the less it can be compressed (With the best not being compressible at all).</p>
<p>This is pretty easily testable by creating a file with decently random data and then trying to compress it by placing it in a <code>zip</code> or similar - the resulting <code>zip</code> will generally be very close in size to your original, and actually be larger in a lot of cases.</p></div>		</li>
					</ul>
	