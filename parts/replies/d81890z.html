	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/you-get-an-upvote" target="_blank">you-get-an-upvote</a>
			<div class="markdown"><p>The &quot;truest&quot; measure of complexity would be &quot;how many bits of information are given (on average) every X bits of sound&quot; (though one could argue it should be something more like &quot;per second&quot;).  This captures how one language could be better at communication than another.  Unfortunately measuring bits is, as far as I know, quite difficult for such a problem, even for the simplified model that just uses IPA and ignores things like body language.  Nonetheless, if you wanted a measurement that has a reasonable mathematical basis and correlates with some &quot;ideal measurement&quot; of complexity, Shannon entropy would probably be a pretty good candidate.</p>
<p>As an example, let's say a language always follows every consonant with the vowel &quot;a&quot;.  Then their &quot;bits-of-information-communicated-per-second&quot; is going to be rather low compared to a language that takes full advantage of vowel-space, b/c (roughly) half of the sounds somebody is hearing yields no information at all (i.e. you could completely preserve the information encoded in the sentence by removing all the &quot;a&quot; sounds).</p>
<p>I would be overjoyed if a linguist performed such analysis on, say, the most common 20 languages.  Maybe we'd have a (very) rough ordering of which language is the most efficient at communicating, or maybe what Linguists have been saying all along is correct, and they'll all be pretty much the same.</p></div>		</li>
					</ul>
	