	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Hypothesis_Null" target="_blank">Hypothesis_Null</a>
			<div class="markdown"><p>describing it another way - Shannon's theorems put limits on the information we can transfer for a given bandwidth and Signal-Noise Ratio (cleaner and louder signal).  But we have not yet reached those limits.  Better technology that can more easily/accurately differentiate changes in the waveform allow us to make more use of it, by using better encoding schemes.</p>
<p>For instance, when you purchase a wifi router, you often see those '802.11a/b/n/g/...' etc indications on them alongside their bit-rates.  These are referencing what encoding schemes are being used by the router. (Your router and device's wifi chip must both be capable of the same encoding to utilize the transfer rates).</p>
<p>The Wifi routers that use some of these newer ~gigabit transfer speeds, are using encoding standards that were established over a decade ago.  The engineers at the time knew exactly what they wanted the encoding scheme to look like - we just didn't have components of sufficient quality/cost to utilize them effectively until more recently.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/freyyr" target="_blank">freyyr</a>
			<div class="markdown"><p>Actually, we have been able to run arbitrarily close to the Shannon Limit since 1993 when Claude Berrou invented turbo codes. They are used in 3G/LTE phone standards </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/miningdroid" target="_blank">miningdroid</a>
			<div class="markdown"><p>Yep. All the math was done in the '90's  and our semiconductor technology is just beginning to catch up to that. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Hypothesis_Null" target="_blank">Hypothesis_Null</a>
			<div class="markdown"><p>Being able to reach the Shannon limit with arbitrary codes is one thing. Actually utilizing them is another.</p>
<p>Else why was 2G not running on turbo codes?  The hardware wasn't up to the task. Something to do with hitting the error-floor too early, if memory serves.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/p1mrx" target="_blank">p1mrx</a>
			<div class="markdown"><p>I think WiFi is already running pretty close to the Shannon limit.  The newer standards extract most of their gains from wider channels (from 20 MHz to 40, 80, and 160) and MIMO (from 1x1 to 2x2, 3x3, and 4x4).</p>
<p>If you start with 802.11g at 54 Mbps, multiply the bandwidth by 8 and the number of MIMO streams by 4, that bumps you to 1728 Mbps trivially.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Hypothesis_Null" target="_blank">Hypothesis_Null</a>
			<div class="markdown"><p>I'm referring to the modulation type and the coding ratio being increased as consumer-level electronics become capable of generating sufficient SNR.</p>
<p><a href="https://static.squarespace.com/static/54860cc3e4b020d690f237ba/548f5703e4b00e8ec160e2fb/548f5707e4b00e8ec160e465/1418680071595/1000w/" target="_blank">Here's a chart</a> of the kind of bit-rate increases based on modulation, coding ratio, and yes, number of spatial-streams.</p>
<p>Point is the wifi standards coming into use had their modulation type, coding ratios, and everything else set in stone long before it was really possible with our signal generators and receivers.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/elsjpq" target="_blank">elsjpq</a>
			<div class="markdown"><p>so what is the limit of the theoretical upper-bound on information density of the &quot;useful&quot; bandwidth of radio frequencies? how close are we to reaching that limit?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Hypothesis_Null" target="_blank">Hypothesis_Null</a>
			<div class="markdown"><p>Channel capacity is:</p>
<p>C = B log2 (1+S/N)</p>
<p>Where B is bandwidth in Hertz, S is signal power, and N is the power of the noise on the channel.  Channel capacity is measured in bits per second.</p>
<p>Your encoding scheme then determines how close to this thetorical maximum you can get. Source coding involves reducing redundant information in your message (compression) and channel coding involves maximizing the use of the channel, and reducing errors via sone form of error-checking.</p></div>		</li>
					</ul>
		</ul>
		</ul>
	