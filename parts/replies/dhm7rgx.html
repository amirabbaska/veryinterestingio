	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/velifer" target="_blank">velifer</a>
			<div class="markdown"><p>I was working through my biostats program in the middle of the contentious infighting between the two schools of thought. Stats packages had begun to really show off what Bayesian methods could do, and it was easy to click a few buttons and get a wrong answer even if you understood most of what you were doing. Bayesian methods were the new hotness, but unproven and easily done wrong, while Frequentist methods were old and busted, but clean and sufficient for most practical purposes.</p>
<p>Here's the thing: it only really matters in academia. In practice, it's just more tools to solve problems. If someone says they're a Frequentist or a Bayesian, they're only half a statistician. Put as many methods and tools in your toolbox as you can. </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/saucissor" target="_blank">saucissor</a>
			<div class="markdown"><p>What do you mean by Bayesian methods being &quot;unproven&quot;?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/velifer" target="_blank">velifer</a>
			<div class="markdown"><p>I was taking classes from some of the hardcore methodologists. They would digress into different approaches to problems, often being ones they were working on. I heard &quot;Then you can do this... ...which seems to work, but we haven't done the proof yet.&quot;</p>
<p>Also, the code people were submitting to STATA and R libraries was still in the early peer-review stages. The old-school frequentists did not trust that at all. Despite things like instrumental variables analysis being ancient, actually applying it within R or STATA got a big nope.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/qwiglydee" target="_blank">qwiglydee</a>
			<div class="markdown"><p>And what is appropriate interpretation of probabity in context of machine learning?
The machine learning can be defined as building function F_w: X â†’ Y, based on observed data of (x, y) pairs. (where w is a set of parameters to be optimized).
It is like creating a belief based of frequencies.</p></div>		</li>
					</ul>
	