	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/crnaruka" target="_blank">crnaruka</a>
			<div class="markdown"><blockquote>
<p>the part of the visual system that senses achromatic contrasts is faster than the part that senses chromatic contrasts.</p>
</blockquote>
<p>What about differences between different colors? I was doing a quick literature search and came upon this paper: <a href="https://www.ncbi.nlm.nih.gov/pubmed/10624952" target="_blank">Perceived Speed of Colored Stimuli</a>. <a href="http://i.imgur.com/bU284b2.png" target="_blank">The main figure in that paper</a> seems to suggest that contrast in the L/M cones was associated with a higher perceived speed then contrast in the S cone. </p>
<p>I'm not sure how to interpret this result. Let's say you have three targets, one green, and red, and one blue, each having the same luminance. If these targets moved across a grey background, would the green and red targets then be perceived to be moving more quickly than the blue target?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/aggasalk" target="_blank">aggasalk</a>
			<div class="markdown"><p>bright/dark is encoded by the L/M cones on vs off, so that is consistent - but the real limit is in the ganglion cells and their descendants in thalamus and beyond, the divergence of the 'magnocellular' and 'parvocellular' pathways - magnocellular descends mostly from pooled L/M responses to encode brightness contrast, and those cells are larger with bigger axons hence faster transmission time.</p>
<p>sorry can't look up any refs at the moment, will try later--</p>
<p><em>edit</em></p>
<p>by the way, if you have an isoluminant image of just reds and greens (but with no brightness difference between them) it is <em>really</em> hard to look at, to even fixate on a feature - i bet tracking moving isoluminant contrasts is super difficult</p>
<p><em>edit2</em></p>
<p>actually sorry i clearly misunderstood your comment, but quick answer is i think it all comes down to luminance contrast - stimuli driving L/M cones for the 'brightness'  signal will have a tracking advantage, since S cones don't converge so much to the brightness signal that advantage is less. same goes for all perceived motion i guess, including 'perceived speed' - motion sources via L/M should be seen more accurately than through S</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/PandaCheeseCake" target="_blank">PandaCheeseCake</a>
			<div class="markdown"><p>I think you are right if you are saying that tracking an object is more of a temporal matter than a spatial one. I did some primary research into the temporal properties of S and L cones and found the CFF (maximum frequency of a flickering dot detectable before it appears as a stationary dot) of S cones to be less than the CFF of L cones for a variety of radiances and eccentricities. Therefore I would suggest that L/M cones would be better at tracking, but I don't know whether L or M would be better.</p>
<p>I know that we are more sensitive to middle-wavelengths and see middle-wavelengths in the dark better, but I'm not sure that this helps in this scenario. </p>
<p>If we take a look at cone densities across the whole retina there are twice as many L cones than M cones (I don't have a source for the fovea, it must be somewhere). Anyway I'm not sure this is useful because the difference in L:M ratio between is hugely variable and designing an experiment would be crazy. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/oberon" target="_blank">oberon</a>
			<div class="markdown"><p>Do you have any examples of an isoluminant of just reds and greens?</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Trailmagic" target="_blank">Trailmagic</a>
			<div class="markdown"><p>Do you happen to have a link to an image that will demonstrate the difficulty of focusing on an isoluminant image?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/purduephotog" target="_blank">purduephotog</a>
			<div class="markdown"><p>Luminance is absolute. Do you mean perceived brightness?</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/igobyplane_com" target="_blank">igobyplane_com</a>
			<div class="markdown"><p>i had heard that bmw used amber for interiors (as they have done a long time now) as it was the most visible.  however it certainly makes sense that the most visible is green.  is there a real reason for this, like it affects night vision looking out on the road the least?  or does bmw just like amber?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/orangenakor" target="_blank">orangenakor</a>
			<div class="markdown"><p>Speculation but, amber is a more &quot;nighttime&quot; color than green, thematically. We associate it with sunset, sunrise, etc. and it is a less artificial looking light than bright green.</p>
<p>More empirically speaking, amber is closer to red. Red light activates and depletes rhodopsin (the primary sensor protein in the intensity sensitive rods) very slowly and is mostly picked up by photopsin in the cones. This means red light is good for maintaining your <a href="https://en.m.wikipedia.org/wiki/Night_vision" target="_blank">night vision</a> and is used for lighting in astronomy, hikers' headlamps, etc. But pure red light is therefore really hard to see contrast in (as that's primarily the rods' job), so making it amber might help compromise. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/iwastheone" target="_blank">iwastheone</a>
			<div class="markdown"><p>Amber should have been chosen over red for stop lights, amber is much more visible to the eye.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/kaspar42" target="_blank">kaspar42</a>
			<div class="markdown"><blockquote>
<p>if you remove all brightness cues from a video, you will have enormous difficulty making sense of what little motion you can see.</p>
</blockquote>
<p>Interesting. Can you link to a video that demonstrates this? </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/BPong_HBong" target="_blank">BPong_HBong</a>
			<div class="markdown"><p>This is great! Your comment shows how someone can use <em>specific</em> terms that are academically heavy, while still sounding sensible and straightforward. Thank you for that. </p>
<p>If you see this comment, I do have a question - </p>
<p>Could this information (or is it already) be used to further the R&amp;D of A.I. visual systems? Like, does this sort of technical understanding translate to something practical in the digital/real world that can be used in A.I.? </p>
<p>I understand you may not be in A.I. - but if you know (or someone reading this) I'd appreciate it if you could drop a few words about it because I've often wondered about it, especially when I see what Google and others are doing, (just search for TED and AI and Vision, you'll find quite a few talks). It only makes sense something like this would help in developing algorithms for distinguishing different elements of a visual.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/aggasalk" target="_blank">aggasalk</a>
			<div class="markdown"><p>i don't know how it would fit into AI, but as i mentioned to someone else, these kinds of facts about visual processing factor heavily into the design of video compression algorithms - long story short, you can just dump the information that humans aren't very sensitive to, which saves a lot of space.</p>
<p><a href="https://en.wikipedia.org/wiki/Chroma_subsampling" target="_blank">https://en.wikipedia.org/wiki/Chroma_subsampling</a></p></div>		</li>
					</ul>
		</ul>
	