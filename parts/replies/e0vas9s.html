	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MaxWelling" target="_blank">MaxWelling</a>
			<div class="markdown"><p>DL is probably always going to play an important role, but we will hit a wall at some point where we are going to search for new tools and principles. I think we will probably integrate DL with more traditional reasoning approaches, but I also think causality and RL are going to play an important role. Especially causality seems crucial if we want models that are interpretable. But it is also known that causal features are far more stable predictors under domain shift: a red car getting into accidents in Italy might be a black car in China. So color is not a causal feature. However, the testosterone level of the driver might be a stable, causal feature for the accidents to happen... </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/fuck_your_diploma" target="_blank">fuck_your_diploma</a>
			<div class="markdown"><blockquote>
<p>we will probably integrate DL with more traditional reasoning approaches</p>
</blockquote>
<p>Would you expand a little on this and list a few new approaches?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/anearthboundmisfit" target="_blank">anearthboundmisfit</a>
			<div class="markdown"><p>Perhaps something like this? <a href="https://arxiv.org/abs/1611.10351v1" target="_blank"><a href="https://arxiv.org/abs/1611.10351v1" target="_blank">https://arxiv.org/abs/1611.10351v1</a></a> (it's from the same Lab)</p></div>		</li>
					</ul>
		</ul>
		</ul>
	