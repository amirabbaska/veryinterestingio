	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/huberemanuel" target="_blank">huberemanuel</a>
			<div class="markdown"><p>I understand your point, I didn't think about the complexity explosion that would cause, thank you!</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/SomeRandomGuydotdot" target="_blank">SomeRandomGuydotdot</a>
			<div class="markdown"><p>More over, there is actually concrete proof that solving zeros of polynomials of degree greater than five do not have general case solutions!</p>
<p>Discovery of this proof was foundation in abstract algebra!</p>
<p>For reference:</p>
<p><a href="https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem" target="_blank">https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem</a></p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/kouhoutek" target="_blank">kouhoutek</a>
			<div class="markdown"><p>Polynomials of degree greater than five <strong>do</strong> have general case solutions.  They do not have solutions that can be expressed using only addition, subtraction, multiplications, division, and radicals.  </p>
<p>This is really no different than saying x^2 - 2 = 0 has no rational solutions, or x^2 + 1 = 0 has no real solutions.  Both have solutions if you introduce new notation, radicals and complex numbers respectively.  Similarly, x^5 + x + 1 = 0 has solutions if you introduce the Bring radical.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ssaltmine" target="_blank">ssaltmine</a>
			<div class="markdown"><p>Basically, no problem in real life is as simple as the ones we see in class. In real life, problems are hard. So, what we do is simplify the problem and make mathematical approximations. Then we can solve those approximations using computer methods.</p>
<p>Our approximations should be reasonably correct as long as we consider certain conditions. For example, a curve can be approximated by a series of small, connected straight lines. If the curve is very curved, we just need to use even more lines, and make sure these are tiny enough to represent the original curve.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/eatingpotatochips" target="_blank">eatingpotatochips</a>
			<div class="markdown"><p>The bigger problem arises from problems where the derivatives of a function are expensive or impossible to compute. What you need for gradient descent to be fast is some way of finding the exact minimum in your line search, but exact line searches don't really exist. In reality, methods such as gradient descent are pretty bad at minimizing functions of just two variables. There are methods which alleviate some issues of gradient descent such as the conjugate gradient method, which seeks to find a better descent path that's not just perpendicular to the contours, but that comes at the cost of a more computationally expensive direction finding algorithm.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/agate_" target="_blank">agate_</a>
			<div class="markdown"><p>To add to this, even for problems with few variables, the it may be impossible to solve the gradient=0 equations.  For instance, f(x,y) = sin(x) sin(y) / (x y) -- the derivatives are easy to calculate, but finding the values of (x,y) where the derivatives are both zero is hard.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/myleslol" target="_blank">myleslol</a>
			<div class="markdown"><p>I'm a 5 year old taking machine learning and differential calculus in kindergarten and this explanation is helpful</p></div>		</li>
					</ul>
	