	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/RockyAstro" target="_blank">RockyAstro</a>
			<div class="markdown"><p>A little more then just evaluating the board.</p>
<p>There are two phases that AlphaGO uses.  </p>
<p>The move phase, uses a neural net to generate a list of decent moves that are fed into a Monte Carlo tree search.  </p>
<p>The evaluation phase is the one you described.</p>
<p>The move phase's net was also &quot;taught&quot; by &quot;watching&quot; a bunch of games as well as self-play.</p>
<p>Personally, the idea of using a neural net to create a list of possible moves that feeds into the MTS was the most interesting aspect of how AlphaGO works.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/KapteeniJ" target="_blank">KapteeniJ</a>
			<div class="markdown"><blockquote>
<p>Step 1: It watched a whole lot of professional go games</p>
</blockquote>
<p>Alphago never saw a single professional go match during its learning. It was primed with relatively strong amateur games</p>
<p>You also skipped policy network.</p></div>		</li>
					</ul>
	