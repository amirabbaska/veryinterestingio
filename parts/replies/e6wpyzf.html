	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/KasianFranks" target="_blank">KasianFranks</a>
			<div class="markdown"><p>The largest datasets we've used have been small at about 100G and specific to a knowledge domain or vertical. This allows for a certain kind of context-control when we combine or factor them with others.</p>
<p>Near real-time data is icing on the cake for us. When we apply models to our own datasets we look to cluster and then augment customers near real-time approaches. However, near real-time clustering has been on the horizon for quite some time for us. Baseline example: <a href="https://www.youtube.com/watch?v=BVFG7fd1H30" target="_blank">https://www.youtube.com/watch?v=BVFG7fd1H30</a></p>
<p>From my observation, we are not close at all to getting a machine to mimic portions of human thought and language. This is largely due to the fact that we can only get as far as our own understanding of human intellect can take us currently. When we can get a machine to understand aspects of poetry or solve a riddle similar to the way a human can we might be half way there. My personal prediction is that machine 'intelligence' might come in a form different from our own.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/discreetecrepedotcom" target="_blank">discreetecrepedotcom</a>
			<div class="markdown"><p>Really enjoyed your answer.  It's depressing being in the know on certain things but that's reality in my view.</p>
<p>I like your technological approach to knowledge systems.  To me that is one of the things that your work is going to improve substantially.  </p>
<p>Thank you for sharing!</p></div>		</li>
					</ul>
		</ul>
	