	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/HoneyBunchesOfGoats_" target="_blank">HoneyBunchesOfGoats_</a>
			<div class="markdown"><p>Serious question: How far away are we from needing to further sophisticate CAPTCHA significantly as bots become smarter?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/serrol_" target="_blank">serrol_</a>
			<div class="markdown"><p>The vast majority of captchas are actually already solved. The real problem is that some people will actually hire farms of people to solve the captchas for them. A bot will go to the page, find a captcha, take a screenshot, send it to a resource center with a whole bunch of people sitting behind computers (generally in China or India), and, for just pennies per captcha, receive the phrase to put in the text box. Again, this kind of service basically costs nothing per captcha, as they're pumping out so many of them that it can't be counted individually.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MonsieurSander" target="_blank">MonsieurSander</a>
			<div class="markdown"><p>There's also a virus that will show a stripping girl. Every time you enter the answer to a captcha she will take off a piece of clothing</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/TheDeza" target="_blank">TheDeza</a>
			<div class="markdown"><p>Yup. You can find sites that advertise ~15c a captcha with an API and everything.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/AlwaysHopelesslyLost" target="_blank">AlwaysHopelesslyLost</a>
			<div class="markdown"><p>Where I work we have just over 250 website clients with many using the CMS that my boss designed and I brought up to date. We use, basically, a hidden textarea. When bots fill it out and we show them the success message/page and throw out the data.</p>
<p>I don't know if I have seen a single junk form submission on the sites that use it</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/tragicshark" target="_blank">tragicshark</a>
			<div class="markdown"><p>That sounds trivial to defeat. It would require a person visit the form and decide which fields to add to posting script.</p>
<p>A significant number of these bots operate (well at least used to when I was in college and ran across them) on IRC boards. Many were simple &quot;form post this blob to that url and regex the result&quot; formats that were generated by little utility tools from a user visiting the form page and selecting the input controls for an activex control to use.</p>
<hr />
<p>Our current solution is:</p>
<ol>
<li>add an http only cookie with new guids for the name and value set to expire in 30 mins (or when the post comes it will be removed)</li>
<li>replace the name for each field on the page with the sha256 hmac of the name followed by the guid value followed by a second guid that is stored on the server and changes every day (the field names are unique to the form every time the page is generated)</li>
<li>use javascript to associate the input tags with their labels which are sent to the browser as div tags (cannot get the fields by parsing the source and matching from labels to fields)</li>
<li>incorporate a honeypot field we expect to be empty on the post (essentially the solution you are describing)</li>
<li>include a hidden field that has a value gets sent as a javascript visible cookie to the browser and placed in as a value on the client (verifies js is running)</li>
<li>for anonymous users, include an image captcha with an audio alternative</li>
<li>immediately reject posts that come back in under 20 seconds</li>
<li>(the big one) manually check every credit card transaction on the gateway when we suspect there was an unusual amount of traffic (we avs verify and address match automatically but if something weird is going on like 2 transactions from a new city we watch it for a day or two)</li>
</ol>
<p>Initially we were being attacked by simple IRC bots (and defeated them with the js running check and then the captcha), followed by what was probably bots mass farming the captchas out to people. These days it tends to be actual people trying with stolen card information. The fraudulent users like us because we take money and let them know it worked but don't give anyone some product back (except tax write-offs and email receipts).</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/GeekPlaya" target="_blank">GeekPlaya</a>
			<div class="markdown"><p>Hm, that's clever. EDIT: But I would imagine many bots are set to ignore hidden inputs. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mcgoogins" target="_blank">mcgoogins</a>
			<div class="markdown"><p>We've seen that method work as well as painting the form with JavaScript. This was a few years ago so maybe nasty spiders are smarter and will evaluate the JavaScript.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Plastonick" target="_blank">Plastonick</a>
			<div class="markdown"><p><a href="http://www.theverge.com/2014/4/16/5621538/google-algorithm-can-solve-recaptcha-almost-every-time" target="_blank">http://www.theverge.com/2014/4/16/5621538/google-algorithm-can-solve-recaptcha-almost-every-time</a></p>
<p>Pretty close it would seem. </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/solepsis" target="_blank">solepsis</a>
			<div class="markdown"><p>Google created reCAPTCHA specifically to make their algorithm better at beating it, so there's that... There's a reason they use house numbers from StreetView as the test.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/AKC-Colourization" target="_blank">AKC-Colourization</a>
			<div class="markdown"><p>At least someone can get their bloody captchas right. </p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/theunderwrittenmusic" target="_blank">theunderwrittenmusic</a>
			<div class="markdown"><p>Actually I just a few weeks ago attended an event that discussed this. You must ALWAYS place protection on credit card submission forms because there are bots that criminals use to figure out if their database of stolen credit cards is valid. So, you don't want to allow a gangster to abuse your service to check that their stolen credit card numbers are valid. </p>
<p>EDIT: To be fair, I don't really mean always.. but if the same user/IP is submitting more than 5 credit card numbers in 10 seconds, you need to do something about it</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Jessie_James" target="_blank">Jessie_James</a>
			<div class="markdown"><p>Excellent point.  Thanks for mentioning that.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/triknodeux" target="_blank">triknodeux</a>
			<div class="markdown"><p>What does spidering a site mean? What do people who use the bots gain from doing this?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Jessie_James" target="_blank">Jessie_James</a>
			<div class="markdown"><p>It is how a search engine finds the content on your site and lets you search for it.  Google, Yahoo, Bing, etc., they all &quot;spider&quot; sites and then you can go to Google.com and type in words to search against what they have found.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/DudeStahp" target="_blank">DudeStahp</a>
			<div class="markdown"><p>Think of a search engine database as a spider web, users can explore everything in that Web like the cute little clueless baby spiders they are. Mama spiders continuously reach out to expand that web, going after juicy insect web pages to feed their babies. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Woosah_Motherfuckers" target="_blank">Woosah_Motherfuckers</a>
			<div class="markdown"><p>You can also have spiders that crawl looking for specific vulnerabilities (versions of unpatched software, open to the world WordPress logins, things like that) so they can then exploit them.</p></div>		</li>
					</ul>
		</ul>
	