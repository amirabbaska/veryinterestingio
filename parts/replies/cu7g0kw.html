	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Ph0X" target="_blank">Ph0X</a>
			<p>It's really fascinating how quickly Deep Learning has been growing recently. I went to a talk last week given by Mike Houston on the different applications of deep learning (fantastic talk). He works at NVIDIA and does machine learning on GPU I believe. The sheer variety of uses was really impressive, and many of those problems where we struggled to get an algorithmic solutions are now getting solved with machine learning.<br><br><a href="http://on-demand.gputechconf.com/siggraph/2015/presentation/SIG1507-Michael-Houston.pdf" target="_blank">Here are the slides</a>, it's definitely nowhere as complete as the actual talk but it gives a good overview.<br><br>EDIT: Oooh, found the recording of the talk!<br><br><a href="http://on-demand.gputechconf.com/siggraph/2015/video/SIG507-Michael-Houston.html" target="_blank">http://on-demand.gputechconf.com/siggraph/2015/video/SIG507-Michael-Houston.html</a></p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/dauntless26" target="_blank">dauntless26</a>
			<p>Is there a video for this talk?</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Ph0X" target="_blank">Ph0X</a>
			<p>I couldn't find it earlier, but I actually looked again and there it was!<br><br><a href="http://on-demand.gputechconf.com/siggraph/2015/video/SIG507-Michael-Houston.html" target="_blank">http://on-demand.gputechconf.com/siggraph/2015/video/SIG507-Michael-Houston.html</a></p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/dauntless26" target="_blank">dauntless26</a>
			<p>Thank you!</p>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ITRAINEDYOURMONKEY" target="_blank">ITRAINEDYOURMONKEY</a>
			<p>One of the cool things about deep learning is that, because artificial neural nets are very good at pattern recognition, we can use them to solve any problem that can be posed as a pattern recognition problem</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/baggerboot" target="_blank">baggerboot</a>
			<p>And the cool thing about that is that many of the hardest problems we've been trying to make AI solve have been pattern recognition problems.</p>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Numendil" target="_blank">Numendil</a>
			<p>I believe Google and Microsoft have also switched to neural networks instead of Hidden Markov Models, not sure about Apple/Nuance</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/danby" target="_blank">danby</a>
			<p>This is probably not a very good way of putting it. It's more like they are adding Neural Network Deep learning projects to the suite of Machine Learning/AI tools they have. They'll undoubtedly continue to use HMMs for the tasks that HMMs excel at.</p>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/TRNogger" target="_blank">TRNogger</a>
			<p>I read an article a while ago that the brains behind Nuance work on a very advanced AI system that seem one step beyond Deep Learning. Where Deep Learning works on a given solution to a problem, they are working on a system that finds the solution to a problem by itself.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/bralra" target="_blank">bralra</a>
			<p>Would you have any links for a layman to learn more about what you two are talking about? </p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/TRNogger" target="_blank">TRNogger</a>
			<p>I don't find the article I stumbled upon which was pretty exhaustive, but on WIRED I found a shorter one and with a great infographic: <a href="http://www.wired.com/2014/08/viv/" target="_blank">http://www.wired.com/2014/08/viv/</a></p>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/JustMakesItAllUp" target="_blank">JustMakesItAllUp</a>
			<p>I find this very amusing (having worked in speech recognition and machine learning over the past couple of decades). It wasn't that long ago if you mentioned neural networks in your abstract you would have a hard time getting it published because they were out of fashion (SVMs were the thing in the noughties).</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Numendil" target="_blank">Numendil</a>
			<p>what about non-negative matrix factorization?</p>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Vimda" target="_blank">Vimda</a>
			<p>IMHO Deep learning is a nicer but less intuitive way to handle sound streams than HMMs</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mljoe" target="_blank">mljoe</a>
			<p>I disagree. One of the things I like about deep learning is it appears to be getting simpler over time (sigmoids vs ReLUs, conv/maxpools to fully convolutional). A lot of cutting edge stuff can be written with half of the code of the older stuff.<br><br>Wouldn't suprise me if the key to AI ends up being something simple and not a super complicated to understand model.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/nsfy33" target="_blank">nsfy33</a>
			<p>I'm not sure what you're disagreeing with... That DL is nicer or less intuitive.<br><br>If the latter, I'm not sure of anything you said counters that. Note that DL can be simpler and less code but still less intuitive. You can explain the general idea of an HMM to a novice or at least what the model learns whereas that's not really possible with DL.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/GuyWithLag" target="_blank">GuyWithLag</a>
			<p>There's a very nice article on <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank">Recurrent Neural Nets</a> that has a very interesting visualization of specific &quot;neurons&quot; vs text features.</p>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Azsu" target="_blank">Azsu</a>
			<p>&gt;that's not really possible with DL<br><br>I've wondered how true this is. Have you ever tried to build an intuition for DL by inspecting the weights or other means?<br><br>I imagine animations of a small network with brightness representing weights (for example) solving a basic problem like a NAND gate then looked at how the training of the weights modified the topology of the solution given the feedback then repeated that process a few times with random initial weights, then I would imagine you could start to build an intuition. Actually, it's pretty hard to deal with different parameters if you don't have at least an intuition for how gradient descent works for understanding problems like local minima.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/GuyWithLag" target="_blank">GuyWithLag</a>
			<p>There's a section on visualization <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank">here</a>, it's worth reading the whole thing.</p>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/timshoaf" target="_blank">timshoaf</a>
			<p>One of the biggest pain points I have about the way neural networks are taught by comparison to say a single <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank">logistic regression</a> unit is that people surround the <a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank">backprop</a> algorithm with this air of mystery or at the least manufactured difficulty, whereas the logreg is just an <a href="https://en.wikipedia.org/wiki/Maximum_likelihood" target="_blank">MLE</a>.<br><br>Well, surprise surprise, backdrop is just a gradient based algorithm as well, and in fact, is just a special case of <a href="https://en.wikipedia.org/wiki/Automatic_differentiation" target="_blank">automatic differentiation</a>. All we are doing is taking the derivative here... we are still just <a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank">hill climbing</a>.</p>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/siblbombs" target="_blank">siblbombs</a>
			<p>What makes it less intuitive? From what I've seen pretty much everyone has gone to RNNs over HMMs for speech at this point.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/UncleMeat" target="_blank">UncleMeat</a>
			<p>Some people don't like the idea that RNNs for speech recognition and other NLP applications seem to ignore a lot of traditional work in linguistic theory. It can be scary to just throw out a lot of structure that we think works well and hope that the RNN figures out either that structure or a better structure. Traditional AI researchers think that RNNs are either too much like black boxes or they remember the brick wall that they hit in the 80s and are worried that it will happen again.<br><br>But in the meantime, it turns out that RNNs are <em>really fucking useful</em> so everybody is getting as much use out of them as possible.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/watamacha" target="_blank">watamacha</a>
			<p>what brick wall did they hit in the 80s?</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/null000" target="_blank">null000</a>
			<p>I'm guessing he's referring to the fact that techniques for creating and training neural networks have been around for ages (60s-80s) but they had limited use for quite a while b/c the data/computational power wasn't around to make them good.<br><br>Most of the advancements as of late have been because more data is available &amp; more fire power can be thrown at each problem, allowing for much larger networks trained to a much higher degree of accuracy.</p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/joelypolly" target="_blank">joelypolly</a>
			<p>This is very true. Social media is a great source of labelled data for training that simply wasn't possible in the 60-80s as well.</p>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/UncleMeat" target="_blank">UncleMeat</a>
			<p>Neural Networks were used successfully to do text recognition for automated check reading but didn't really see a lot of successful applications other than that. A lot of researchers wrote them off and it wasn't until decades later that, with more computing power and some more clever approaches, they became useful in so many problem domains.</p>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/CaptKrag" target="_blank">CaptKrag</a>
			<p>Do you have any sources on that? </p>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/siblbombs" target="_blank">siblbombs</a>
			<p>People from Toronto brought it to google back in <a href="https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/clyjgbf" target="_blank">2012</a>, and it has been rolled out to a <a href="http://googleresearch.blogspot.com/2015/08/the-neural-networks-behind-google-voice.html" target="_blank">lot of other stuff</a> at Google.<br><br>Baidu has also done a lot of work in this area, their <a href="http://www.forbes.com/sites/patrickmoorhead/2015/03/27/nvidia-gtc-the-race-to-perfect-voice-recognition-using-gpus/" target="_blank">speech system</a> is also based on RNNs.<br><br>Skype's real time translation service is most likely powered by RNNs, they haven't confirmed it but Microsoft has been one of the active researchers in deep learning and the idea of using RNNs for translation is very popular right now. <a href="http://googleresearch.blogspot.com/2015/07/how-google-translate-squeezes-deep.html" target="_blank">Google Translate</a> is mostly based around deep learning.</p>		</li>
					</ul>
		</ul>
		</ul>
		</ul>
	