	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ReasonablyBadass" target="_blank">ReasonablyBadass</a>
			<div class="markdown"><p>3 million from each eye is still massive. Thanks for the answer!</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/albasri" target="_blank">albasri</a>
			<div class="markdown"><p>Indeed. That is what forms the blind spot -- you have to get the signal out of the eye somehow and the only way out is to punch a hole through the retina. The blind spot corresponds to the region of the retina where there are no photoreceptors. Increasing the resolution of the representation therefore comes at the cost of having a larger and larger blind spot (although some small percentage of ganglion cells are photosensitive, so there is some nuance here). <a href="https://en.m.wikipedia.org/wiki/Cephalopod_eye" target="_blank">Some eyes</a> like the octopus's are organized differently and don't have a blind spot.</p>
<p>Edit: see /u/JohnShaft's comments/ discussion below</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Varkoth" target="_blank">Varkoth</a>
			<div class="markdown"><p>I always thought the anatomy of the eye was a clear case against intelligent design.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/DeathtoPedants" target="_blank">DeathtoPedants</a>
			<div class="markdown"><p>Does the size of the blind spot vary between individuals? </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/topoftheworldIAM" target="_blank">topoftheworldIAM</a>
			<div class="markdown"><p>Quick activity I use in my class to find the blind spot.</p>
<p><a href="https://www.exploratorium.edu/snacks/blind-spot" target="_blank">https://www.exploratorium.edu/snacks/blind-spot</a></p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/JohnShaft" target="_blank">JohnShaft</a>
			<div class="markdown"><p>3 million for each eye is a significant over-estimate, at least according to the best scientific estimates used.   </p>
<p><a href="http://www.sciencedirect.com/science/article/pii/S0161642089327187" target="_blank">http://www.sciencedirect.com/science/article/pii/S0161642089327187</a><br />
<a href="http://iovs.arvojournals.org/article.aspx?articleid=2161180" target="_blank">http://iovs.arvojournals.org/article.aspx?articleid=2161180</a>  </p>
<p>It is also interesting that the optic nerve ALSO has efferent axons that are largely ignored in these estimates.   </p>
<p><a href="http://www.sciencedirect.com/science/article/pii/S0006899300027062" target="_blank">http://www.sciencedirect.com/science/article/pii/S0006899300027062</a>  </p>
<p>The number of RGCs in each eye that project centrally is roughly equal to the number of sensory afferents on each side of the body - and both are orders of magnitude more than the number of 8th nerve fiber afferents.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/albasri" target="_blank">albasri</a>
			<div class="markdown"><p>Thanks for pointing this out. I'm not totally familiar with this research, but I am aware that there are different counting methods, so for example <a href="http://onlinelibrary.wiley.com/doi/10.1002/1097-0185(20001001\)260:2%3C124::AID-AR20%3E3.0.CO;2-D/full" target="_blank">this</a> paper gives counts of 2-3 million for ganglion cells in young eyes (which may be different from the number of fibers if you look at the nerve instead). </p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/addisonhammer" target="_blank">addisonhammer</a>
			<div class="markdown"><p>I don't think 3M &quot;pixels&quot; is really the answer, though, since the retina functions so completely differently from a CCD chip.</p>
<p>The preprocessing reduces the signal to &quot;metadata&quot;, so each ganglion isn't really reporting &quot;I'm a yellow pixel&quot;... They are performing matrix calculations on gradients of light and color, relative motion, patterns, etc. This means they are transmitting info like &quot;this is the fuzzy edge of a yellow region that is moving slowly&quot;. Your brain can later fill in the yellow region using this &quot;metadata&quot; (this is actually how many optical illusions work... The preprocessing makes assumptions/mistakes)</p>
<p>This processing stacks up in layers from the retina, all the way to the visual cortex, where you can make the determination: &quot;That is a yellow cat&quot;. A neural net is a closer approximation than a camera/photo.</p>
<p>Source: Took a grad-level physiology course for funzies. It was one of the more interesting  classes I've ever taken.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/cutelyaware" target="_blank">cutelyaware</a>
			<div class="markdown"><p>I think this is the key idea. The fallacy people have is that images get stored in the brain, but the images are long gone by the time the data exits the eye. The data going over the wire is closer to someone describing it by phone. That's your metadata. Nobody has that classic &quot;photographic memory&quot; seen in movies that can be recalled and scanned for new data. Data that wasn't initially extracted is completely lost. For example, if you look at a bookshelf, you may see three shelves, each with many books. If someone were to later ask you how many books were there on the middle shelf, the best you could answer is &quot;many&quot; because that's the entirety of your memory, even though you eyes had much more data at the time.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Rirere" target="_blank">Rirere</a>
			<div class="markdown"><p>I will note that computational photography is an emerging discipline that has aimed to use similar approaches, both in order to open up new types of cameras (such as the flexible, lensless &quot;sheet&quot; camera) as well as to compensate for deficiencies in existing designs (the small sensors on cell phones, for example).</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/yojimbojango" target="_blank">yojimbojango</a>
			<div class="markdown"><p>From the 'pixel' analogy, it's like saying that your eye transmits animated gifs instead of bitmaps.  Your eye doesn't transmit a fresh pixel to the brain, it sends changes (of various types).  For more information see /r/brokengifs/</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Dr_Who-gives-a-fuck" target="_blank">Dr_Who-gives-a-fuck</a>
			<div class="markdown"><p>Fun fact, <a href="https://youtu.be/hKSlewfW_5Q?t=118" target="_blank">they're working on foveated rendering for video games</a>.  They track where your eyes are looking on the screen and render only a small circle section in full resolution and it gradually decreases in resolution away from the center of the area of focus.  Because only a small portion of the screen is rendered at full resolution, a lot of GPU horsepower is freed up.  This means they could crank up the graphics to super ultra with the freed up horsepower.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/F0sh" target="_blank">F0sh</a>
			<div class="markdown"><blockquote>
<p>This means that a weaker signal is more likely to be detected in the periphery because it's getting pooled. That's part of the reason why it's easier to see dim stars out of the corner of your eye rather than looking right at them.</p>
</blockquote>
<p>Shouldn't this also accompany the star looking larger and blurrier? The explanation I always heard, and which sounds more plausible, is that the fovea contains virtually no rod cells, so weak light sources can't be detected by the less-sensitive cones. It seems to me that pooling would only result in better low-light sensitivity when detecting objects whose image falls across multiple photoreceptors, but a star has a tiny angular size (I looked up two - Betelgeuse and Denebola, which are 0.05 and 0.0007 arc seconds, respectively) - much, much smaller than the eye's maximum angular resolution of around 60 arc seconds.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/throwaway131072" target="_blank">throwaway131072</a>
			<div class="markdown"><p>Yes, rods are also faster so that's why some people can see fluorescent lights flicker from the 50/60hz power grid out of the corner of their eye.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/albasri" target="_blank">albasri</a>
			<div class="markdown"><p>It is the case that rods are more sensitive than cones and there indeed are more rods in the periphery than cones. I didn't want to go too far afield, which is why I said &quot;part of the reason&quot;. </p></div>		</li>
					</ul>
		</ul>
	