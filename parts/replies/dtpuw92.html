	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/greysplash" target="_blank">greysplash</a>
			<div class="markdown"><p>Similarly, film on non-digital cameras is the same as the image sensor. The rectangular film will only produce a rectangular photo.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/SirMildredPierce" target="_blank">SirMildredPierce</a>
			<div class="markdown"><p>It's not a property of the film which produces the shape of the image, but the camera itself, <a href="https://i2.wp.com/simonhawketts.co.uk/wp-content/uploads/2016/02/agfa-super-silette-l-35mm-rangefinder-camera-inside-the-film-chamber.jpg" target="_blank">specifically the shape of the window which the light passes through</a>.  If I were to use the <a href="http://thedelightsofseeing.blogspot.com/2010/10/pinhole-photography-and-camera-obscura.html" target="_blank">same film in a homemade pinhole camera</a>, you'd see the image spill over the area used by a standard camera and cover the entire film.</p>
<p>The frame in a standard camera helps keep things nice and tidy on the film roll, without the frame limiting the image area images would potentially overlap with one and other.  In single film or plate cameras the frame is what physically holds the film or plate in place, and usually the frame is irregularly shaped as opposed to strictly rectangular.  There's no inherent quality about the film which produces the rectangular shape.  A rectangular film can produce any shape of photo, depending on the frame it is shooting through.</p>
<p>Some specialty cameras have unusual film and lens setups and result in circular images.  Two examples I can think of are <a href="https://mymodernmet.com/carl-stormer-hidden-camera-photography/" target="_blank">the camera Carl Størmer used to take secret pictures around Oslo</a> over a hundred years ago, and the observatory camera used on Apollo 16 to <a href="http://www3.telus.net/summa/faruv/index.htm" target="_blank">photograph the stars and the Earth in the UV spectrum</a>.  <del>Both of these cameras, like the pinhole cameras, are custom made.</del></p>
<p>EDIT: I had erroneously assumed that Størmer's camera was custom made, but in fact it was a mass-produced camera designed specifically for taking secret photos.  It was known as <a href="https://steemit.com/photography/@chandravibha/images-taken-with-hidden-spy-camera-in-1890s" target="_blank">C. P. Stern's Patented Concealed Vest Camera</a>.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/dtercz" target="_blank">dtercz</a>
			<div class="markdown"><p>The quality of the Carl Størmer photographs are really impressive! It is quite surprising. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/frothface" target="_blank">frothface</a>
			<div class="markdown"><p>Wow. That sheds a whole new light on what life was like. Usually people tried to look serious in photos from that era.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/L96" target="_blank">L96</a>
			<div class="markdown"><p>True, but if you have a strip of film with a continuous width, it makes more sense to use rectangular frames as you won't waste film.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Collymotion" target="_blank">Collymotion</a>
			<div class="markdown"><p>I just want to mention an additional note: The way an image sensor is set in a digital camera is based on film cameras. Specifically a full-frame sensor has the same dimensions as 35mm film (the most widely used film). This is why it’s a rectangle and not, say, a perfect square or circle.  </p>
<p>Certain cameras use what is called a crop sensor. They have smaller dimensions than full-frame. Using the same lens on a crop sensor camera and a full-frame camera will produce different results because of this. </p>
<p>Edit: Someone replied (then deleted it) that a crop sensor's photograph is only a crop of a full-frame one. This isn't exactly true, so I wanted to mention that <a href="https://www.slrlounge.com/workshop/crop-vs-full-frame-cameras/" target="_blank">a crop sensor will change the relative focal length and depth of field of a lens</a>. It doesn't make for a huge downside or issue, but photographers do a little simple mental math to account for this.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/L96" target="_blank">L96</a>
			<div class="markdown"><p>To give even more detail, the standard DSLR sensor size is from a little-used and obsolete 1990s film format known as APS, which is smaller than 35mm.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/bananadingding" target="_blank">bananadingding</a>
			<div class="markdown"><p>To finish off your list there is also Medium and Large Format film cameras and digital medium format, with medium format  at 120mm, 135mm, and large format starting at 4x5” and going up from there</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/absynthekc" target="_blank">absynthekc</a>
			<div class="markdown"><p>The lens is round, but the aperture is square, right?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/crankyfrankyreddit" target="_blank">crankyfrankyreddit</a>
			<div class="markdown"><p>Apertures, due to needing to be able to grow or shrink, are made up of a set of flat blades, usually around seven.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/SirMildredPierce" target="_blank">SirMildredPierce</a>
			<div class="markdown"><p>Some apertures can be square, there's all sorts of shapes, usually round and symmetrical.  But the shape of the aperture has nothing to do with the shape of the resulting image.  You <em>can</em> see the shape of the aperture in points of light on the image which are out of focus, i.e. the shape of the <a href="https://en.wikipedia.org/wiki/Bokeh" target="_blank">bokeh</a>.</p>
<p>The adjustable aperture inside a camera usually uses a series of blades that can expand or contract depending on what f-stop you want.  Many Canon cameras <a href="https://en.wikipedia.org/wiki/File:Bokeh_Example.jpg" target="_blank">use 8 sided blades, so you get bokeh like this</a>.</p>
<p><a href="https://static1.squarespace.com/static/54b88f6ee4b05e2e7fc32ae8/t/54be3b04e4b0a3e130f24534/1421753095772/bokehshape.jpg" target="_blank">If you introduce irregularly shaped apertures in to the lens stack somewhere, you'll get irregularly shaped bokeh.</a></p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/anonymfus" target="_blank">anonymfus</a>
			<div class="markdown"><blockquote>
<p>Partly it's just tradition, but it's also that many are made on a big silicon wafer and then cut apart. If they were round, there would be wasted space.</p>
</blockquote>
<p>Actually rectangular shape is a wafer cutting technology limitation. Silicon wafer is round, so hexagonal shape would be more effective.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/tuctrohs" target="_blank">tuctrohs</a>
			<div class="markdown"><p>Yes, I agree that it's the dicing technology that requires rectangles devoted to each sensor.  If you wanted circular sensors, you would need to cut squares and waste some of the area, unless you got exotic new technology that's recently been introduced to dice wafers in shapes like hexagons, which would waste less space when used for circular sensors.</p>
<p>However, the round shape of the wafer doesn't have much to do with it.  If you look at the <a href="https://www.researchgate.net/profile/Sung_Yi2/publication/27611616/figure/fig6/AS:340543868555267@1458203393176/Fig-9a-CMOS-Image-sensor-wafer-after-WLP-Backside.ppm" target="_blank">layout of an actual image sensor wafer</a>, it's not that much different from <a href="https://i.stack.imgur.com/jiMwt.png" target="_blank">what you might get packing hexagons in a circle</a>
you can pack more area of hexagons into a circle than you can rectangles, but the improvement in total sensor area you'd get from a chip would be pretty minor, given that the sensors are small compared to the chip size.  </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/jarfil" target="_blank">jarfil</a>
			<div class="markdown"><blockquote>
<p>If you wanted circular sensors, you would need to cut squares and waste some of the area</p>
</blockquote>
<p>You could have circular sensors, then fill the space up to a square shape with extra electronics... but that's been rendered moot by the 3D wafer stacking technology; now you can have the electronics <em>below</em> the photodiode array, instead of <em>to the side</em> of it.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/classified_documents" target="_blank">classified_documents</a>
			<div class="markdown"><p>In the digital age would'nt rectangular images be more easier to work with as they lend itself to 2d matrix operations too? (It might be possible to transform a hexagonal coordinate system to this, my knowledge of linear algebra is very fuzzy)</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/RiPont" target="_blank">RiPont</a>
			<div class="markdown"><p>No, it's just math.</p>
<p><strong>All</strong> image data is actually just a <em>linear</em> stream of bits grouped into bytes in a linear fashion representing a big bag of pixels.  Computer memory is virtualized into one big linear address space.</p>
<p>The math for translating that set of pixels into (x,y) coordinates is easy for laypersons to understand.  For an oversimplified example, imagine each pixels was one byte and the image was 100x100 pixels.  Well, the byte at position 0 is the first pixel on the first line.  Position 100 represents the first pixel on the second line.  200 for the third line, and so on.</p>
<p>But the math for translating it in to a hex image would be just as easy for a computer.  0 is still the first pixel in the first row, but the rows aren't the same size.  The computer would still store all the bytes in a linear fashion.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/peasncarrots20" target="_blank">peasncarrots20</a>
			<div class="markdown"><p>There's no &quot;limitation&quot;, it's a matter of scale. For example, CCD cameras are considered to be intrinsically better than CMOS- but because the vast majority of chips in the world are made with CMOS, the CMOS cameras have huge economies of scale and have advanced technologically further than CCD cameras, closing the gap.</p>
<p>Your camera is affordable &amp; high performance because it shares so much technology with other types of chips. A hexagonal shape would be &quot;superior&quot;, but at the end of the day you can get more for your money by sharing the rectangle shape everyone else uses.</p>
<p>The bit, maybe from Top Gear, where a budget 90's or 00's minivan beats the pants off a schnazzy old 50's or 60's Porsche, comes to mind for some reason.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/jarfil" target="_blank">jarfil</a>
			<div class="markdown"><blockquote>
<p>CCD cameras are considered to be intrinsically better than CMOS</p>
</blockquote>
<p>Not really. CCD sensors are much slower, and the latest 3D and backside-illuminated (BSI) CMOS sensors have pretty much closed the gap in terms of sensitivity and die size.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/InternetCrank" target="_blank">InternetCrank</a>
			<div class="markdown"><p>Are the camera sensors concave to match the incoming light direction from the lens, or is the aberration at the edges corrected digitally or something? </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Klexal" target="_blank">Klexal</a>
			<div class="markdown"><p>Image sensors are flat. If there are any chromatic aberrations in the final image, it's usually the result of poor light transmission through the lens (due to refraction separating wave lengths) rather than the shape of the image sensor.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Thesleepingjay" target="_blank">Thesleepingjay</a>
			<div class="markdown"><p>There is some research going on to see if curved sensors would be viable. Pretty nest stuff.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/gmurray81" target="_blank">gmurray81</a>
			<div class="markdown"><p>Interestingly, people are so used to these abberations, that some video games fake them to make a game seem more filmic.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/thedailynathan" target="_blank">thedailynathan</a>
			<div class="markdown"><p>Well the OP asked for aberrations in general, and that's a matter of perspective. For example the barrel/pincushion distortion is an aberration solely due to projecting a naturally spherical view onto a flat imaging plane. If we had a concave spherical imaging surface (our eyes are a great example!), we wouldn't need any special lens design to deal with barrel distortion. With our current engineering technology it's easier to correct this in the lens, but a sensor-side approach is also valid. It is not the lenses' &quot;fault&quot; that this aberration occurs.</p>
<p>Coma aberration can be viewed the same way as well.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/petem8" target="_blank">petem8</a>
			<div class="markdown"><p>They're flat in consumer devices, but in some specialist applications where focus &amp; image quality across the whole frame is important, they can be curved. Best example I can think of is the Kepler Space Telescope:</p>
<p><a href="https://en.wikipedia.org/wiki/Kepler_(spacecraft)#/media/File%3AKeplerspacecraft-FocalPlane-cutout.svg" target="_blank">https://en.wikipedia.org/wiki/Kepler_(spacecraft)#/media/File%3AKeplerspacecraft-FocalPlane-cutout.svg</a></p>
<p>Edit: I guess it's more correct to say the Kepler array is curved, the individual CCD chips making up the array are still flat.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/marcan42" target="_blank">marcan42</a>
			<div class="markdown"><p>Camera sensors are flat, and most typical lenses are designed to produce a flat and non-distorted image (more properly called <em>rectilinear</em>, where straight lines are straight and parallel horizontal or vertical lines stay parallel). However, some cameras (particularly compact ones) trade off that aspect for making the lens more compact or better within a given size. This produces a distorted image which is then corrected digitally by the processor in the camera. For example, my Canon S100 spits out normal processed JPEG images that look like <a href="https://marcan.st/transf/s100_tiles_jpeg.jpg" target="_blank">this</a>, but the image that the sensor actually captures looks like <a href="https://marcan.st/transf/s100_tiles_raw2.jpg" target="_blank">this</a>. Note how you can see further along the corners thanks to the distortion, but that part of the image is cropped off after the automatic in-camera correction. You can get the raw image by asking the camera to save a RAW file, which contains the unprocessed sensor data. Canon's software automatically corrects it too, but third-party software will show you the original distorted image.</p>
<p>Some cameras like GoPros, and some lenses for interchangeable lens cameras, are designed for wider fields of view and forgo the rectilinear aspect, because making rectilinear lenses with very wide fields of view is difficult or impossible. These are called <em>fisheye</em> lenses. You can also correct images taken with these lenses after the fact in software, if you want to, but the correction won't happen automatically in the camera.</p>
<p>Edit: In all of these cases the sensor is still flat and the lens is still specifically designed to focus light on the plane of the sensor (regardless of how shapes in the image are distorted, they're still in focus), mostly because making sensors that aren't flat isn't really practical. Some <a href="https://en.wikipedia.org/wiki/Petzval_lens" target="_blank">historical lenses</a> didn't correct for this properly, resulting in images that are focused in the center but out of focus towards the edges.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/IM_OK_AMA" target="_blank">IM_OK_AMA</a>
			<div class="markdown"><p>Here's a fun image of what a rectilinear converted image looks like minus the cropping: <a href="https://imgur.com/a/j8EJG" target="_blank">https://imgur.com/a/j8EJG</a></p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/burritoemoji" target="_blank">burritoemoji</a>
			<div class="markdown"><p>Lens distortion is not the same as field curvature. Guy above you was asking why sensors are not curved. Your s100 definitely has a flat sensor. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MattieShoes" target="_blank">MattieShoes</a>
			<div class="markdown"><blockquote>
<p>flat and non-distorted image</p>
</blockquote>
<p>Impossible.  </p>
<blockquote>
<p>properly called rectilinear</p>
</blockquote>
<p>Rectilinear is just picking the <em>type</em> of distortion present.  :-)</p></div>		</li>
					</ul>
		</ul>
		</ul>
	